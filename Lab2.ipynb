{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and converting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\".\\Dataset\\kc_house_data.csv\")\n",
    "# # Display the shape of the dataset, a total of 21613 samples, each sample has 21 different kinds of information.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650     1.0           0     0          3      7        1180   \n",
       "1      7242     2.0           0     0          3      7        2170   \n",
       "2     10000     1.0           0     0          3      6         770   \n",
       "3      5000     1.0           0     0          5      7        1050   \n",
       "4      8080     1.0           0     0          3      8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the number of rows to 25\n",
    "pd.options.display.max_columns = 25\n",
    "# display the first five lines (default)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has a total of 21,613 housing data, and each house sample has 21 different information, the codes indicate the following meanings:\n",
    "-\tid: The identification code of the house.\n",
    "-\tdate: The date the house was sold.\n",
    "-\tprice: Housing price (target).\n",
    "-\tbedrooms: Number of bedrooms.\n",
    "-\tbathrooms: Number of bathrooms.\n",
    "-\tsqft_living: The area of the apartments interior living space (square feet).\n",
    "-\tsqft_lot: The area of the land space (square feet).\n",
    "-\tfloors: The total floors of the house.\n",
    "-\twaterfront: A variable for whether the apartment was overlooking the waterfront or not.\n",
    "-\tview: An index of how good the view of the property was\n",
    "-\tcondition: An index on the condition of the apartment.\n",
    "-\tgrade: An index for rating building construction and design (according to the King County scoring system).\n",
    "-\tsqft_above: The area of the interior housing space that is above ground level (square feet).\n",
    "-\tsqft_basement: The area of the interior housing space that is below ground level (square feet).\n",
    "-\tyr_built: Building time.\n",
    "-\tyr_renovated: The last renovation time of the house.\n",
    "-\tzipcode: ZIP code that the house is in.\n",
    "-\tlat: Latitude coordinates.\n",
    "-\tlong: Longitude coordinates.\n",
    "-\tsqft_living15: The square footage of living space recorded in 2015 (implies some renovations)\n",
    "-\tsqft_lot15: The square footage of land lots recorded in 2015. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data type: There are five types of data: object (string), Boolean, integer, float, and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms           int64\n",
       "bathrooms        float64\n",
       "sqft_living        int64\n",
       "sqft_lot           int64\n",
       "floors           float64\n",
       "waterfront         int64\n",
       "view               int64\n",
       "condition          int64\n",
       "grade              int64\n",
       "sqft_above         int64\n",
       "sqft_basement      int64\n",
       "yr_built           int64\n",
       "yr_renovated       int64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data type: \n",
    "Because the date data in the dataset is in a string type while the input of the model only accepts a numeric type, date data including year, month, and day are converted into the numeric values through the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7        1180              0      1955             0   \n",
       "1     0          3      7        2170            400      1951          1991   \n",
       "2     0          3      6         770              0      1933             0   \n",
       "3     0          5      7        1050            910      1965             0   \n",
       "4     0          3      8        1680              0      1987             0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  year  month  day  \n",
       "0    98178  47.5112 -122.257           1340        5650  2014     10   13  \n",
       "1    98125  47.7210 -122.319           1690        7639  2014     12    9  \n",
       "2    98028  47.7379 -122.233           2720        8062  2015      2   25  \n",
       "3    98136  47.5208 -122.393           1360        5000  2014     12    9  \n",
       "4    98074  47.6168 -122.045           1800        7503  2015      2   18  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numeric values\n",
    "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))\n",
    "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
    "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
    "\n",
    "# Delete useless data, inplace is to save the updated data to the original place\n",
    "data.drop(['id'], axis=\"columns\", inplace=True)\n",
    "data.drop(['date'], axis=\"columns\", inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data division \n",
    "Split data: Divide dataset into three sets: training data, validation data, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.shape[0]\n",
    "# Get a random index equal to the number of data,\n",
    "indexes = np.random.permutation(data_num)\n",
    "# Randomly divide data into Train, validation and test. The division ratio here is 6:2:2\n",
    "train_indexes = indexes[:int(data_num *0.6)]\n",
    "val_indexes = indexes[int(data_num *0.6):int(data_num *0.8)]\n",
    "test_indexes = indexes[int(data_num *0.8):]\n",
    "# Retrieve training data, validation data and test data \n",
    "train_data = data.loc[train_indexes]\n",
    "val_data = data.loc[val_indexes]\n",
    "test_data = data.loc[test_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Standard Score is used to standardize the data, which is formulated as follows. \n",
    "x_norm=(x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_validation_data = pd.concat([train_data, val_data])\n",
    "mean = train_validation_data.mean()\n",
    "std = train_validation_data.std()\n",
    "\n",
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training data in Numpy array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data.drop('price', axis='columns'))\n",
    "y_train = np.array(train_data['price'])\n",
    "x_val = np.array(val_data.drop('price', axis='columns'))\n",
    "y_val = np.array(val_data['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 12967 training samples, and each sample has 21 kinds of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12967, 21)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Training Network Model\n",
    "\n",
    "1.\tBuild a fully connected neural network, named model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a fully connected neural network\n",
    "model = keras.Sequential(name='model-1')\n",
    "# # The first fully connected layer is set to 64 neurons, and the input shape is set to (21, ), \n",
    "# but in fact the shape of the data we input is (batch_size, 21)\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "#The second fully connected layer (64 neurons)\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# The output fully connected layer ( 1 neuron).\n",
    "model.add(layers.Dense(1))\n",
    "# Display network model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tSet the optimizer, loss function, metric function and callback function.\n",
    "\n",
    "•\tSet the optimizer, loss function, metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tCreate a directory to save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'lab2-logs/models/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-2ed70c752279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lab2-logs/models/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hieu\\appdata\\local\\programs\\python\\python38\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'lab2-logs/models/'"
     ]
    }
   ],
   "source": [
    "model_dir = 'lab2-logs/models/'\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tSet the callback function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard callback function helps record training information and save as TensorBoard log file\n",
    "log_dir = os.path.join('lab2-logs', 'model-1')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "# ModelCheckpoint helps to save the network model, \n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-1.h5', \n",
    "                                        monitor='val_mean_absolute_error', \n",
    "                                        save_best_only=True, \n",
    "                                        mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tTraining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 15s - loss: 0.2048 - mean_absolute_error: 0.1599WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_begin` time: 0.0120s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.1449s). Check your callbacks.\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0376 - mean_absolute_error: 0.1345 - val_loss: 0.1367 - val_mean_absolute_error: 0.2167\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 913us/step - loss: 0.0309 - mean_absolute_error: 0.1265 - val_loss: 0.1318 - val_mean_absolute_error: 0.2125\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 902us/step - loss: 0.0267 - mean_absolute_error: 0.1213 - val_loss: 0.1373 - val_mean_absolute_error: 0.2172\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 917us/step - loss: 0.0260 - mean_absolute_error: 0.1199 - val_loss: 0.1353 - val_mean_absolute_error: 0.2143\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0270 - mean_absolute_error: 0.1220 - val_loss: 0.1376 - val_mean_absolute_error: 0.2166\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0267 - mean_absolute_error: 0.1215 - val_loss: 0.1351 - val_mean_absolute_error: 0.2155\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0261 - mean_absolute_error: 0.1203 - val_loss: 0.1356 - val_mean_absolute_error: 0.2160\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0275 - mean_absolute_error: 0.1230 - val_loss: 0.1325 - val_mean_absolute_error: 0.2156\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0301 - mean_absolute_error: 0.1260 - val_loss: 0.1572 - val_mean_absolute_error: 0.2245\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0325 - mean_absolute_error: 0.1297 - val_loss: 0.1406 - val_mean_absolute_error: 0.2190\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0339 - mean_absolute_error: 0.1334 - val_loss: 0.1402 - val_mean_absolute_error: 0.2235\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0278 - mean_absolute_error: 0.1229 - val_loss: 0.1396 - val_mean_absolute_error: 0.2213\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0279 - mean_absolute_error: 0.1229 - val_loss: 0.1406 - val_mean_absolute_error: 0.2172\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0292 - mean_absolute_error: 0.1264 - val_loss: 0.1340 - val_mean_absolute_error: 0.2152\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0277 - mean_absolute_error: 0.1222 - val_loss: 0.1366 - val_mean_absolute_error: 0.2185\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.0263 - mean_absolute_error: 0.1206 - val_loss: 0.1380 - val_mean_absolute_error: 0.2163\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0268 - mean_absolute_error: 0.1211 - val_loss: 0.1371 - val_mean_absolute_error: 0.2178\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 935us/step - loss: 0.0280 - mean_absolute_error: 0.1239 - val_loss: 0.1427 - val_mean_absolute_error: 0.2175\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0291 - mean_absolute_error: 0.1259 - val_loss: 0.1424 - val_mean_absolute_error: 0.2257\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0308 - mean_absolute_error: 0.1269 - val_loss: 0.1499 - val_mean_absolute_error: 0.2306\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 935us/step - loss: 0.0316 - mean_absolute_error: 0.1286 - val_loss: 0.1464 - val_mean_absolute_error: 0.2224\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 955us/step - loss: 0.0291 - mean_absolute_error: 0.1241 - val_loss: 0.1380 - val_mean_absolute_error: 0.2150\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0267 - mean_absolute_error: 0.1215 - val_loss: 0.1382 - val_mean_absolute_error: 0.2181\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 935us/step - loss: 0.0268 - mean_absolute_error: 0.1217 - val_loss: 0.1395 - val_mean_absolute_error: 0.2172\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 941us/step - loss: 0.0259 - mean_absolute_error: 0.1194 - val_loss: 0.1398 - val_mean_absolute_error: 0.2234\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.0263 - mean_absolute_error: 0.1213 - val_loss: 0.1417 - val_mean_absolute_error: 0.2207\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0294 - mean_absolute_error: 0.1265 - val_loss: 0.1442 - val_mean_absolute_error: 0.2214\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0269 - mean_absolute_error: 0.1223 - val_loss: 0.1412 - val_mean_absolute_error: 0.2190\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0267 - mean_absolute_error: 0.1220 - val_loss: 0.1391 - val_mean_absolute_error: 0.2201\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 711us/step - loss: 0.0272 - mean_absolute_error: 0.1223 - val_loss: 0.1421 - val_mean_absolute_error: 0.2205\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 917us/step - loss: 0.0340 - mean_absolute_error: 0.1325 - val_loss: 0.1380 - val_mean_absolute_error: 0.2161\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0330 - mean_absolute_error: 0.1308 - val_loss: 0.1377 - val_mean_absolute_error: 0.2148\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0273 - mean_absolute_error: 0.1227 - val_loss: 0.1385 - val_mean_absolute_error: 0.2181\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0269 - mean_absolute_error: 0.1216 - val_loss: 0.1439 - val_mean_absolute_error: 0.2213\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0269 - mean_absolute_error: 0.1223 - val_loss: 0.1421 - val_mean_absolute_error: 0.2257\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 806us/step - loss: 0.0264 - mean_absolute_error: 0.1206 - val_loss: 0.1398 - val_mean_absolute_error: 0.2155\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0268 - mean_absolute_error: 0.1213 - val_loss: 0.1407 - val_mean_absolute_error: 0.2235\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0272 - mean_absolute_error: 0.1218 - val_loss: 0.1371 - val_mean_absolute_error: 0.2156\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0276 - mean_absolute_error: 0.1224 - val_loss: 0.1381 - val_mean_absolute_error: 0.2191\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 836us/step - loss: 0.0280 - mean_absolute_error: 0.1230 - val_loss: 0.1393 - val_mean_absolute_error: 0.2195\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.0283 - mean_absolute_error: 0.1233 - val_loss: 0.1440 - val_mean_absolute_error: 0.2217\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0260 - mean_absolute_error: 0.1203 - val_loss: 0.1394 - val_mean_absolute_error: 0.2205\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0263 - mean_absolute_error: 0.1209 - val_loss: 0.1383 - val_mean_absolute_error: 0.2228\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0262 - mean_absolute_error: 0.1206 - val_loss: 0.1403 - val_mean_absolute_error: 0.2170\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0254 - mean_absolute_error: 0.1193 - val_loss: 0.1411 - val_mean_absolute_error: 0.2190\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0257 - mean_absolute_error: 0.1200 - val_loss: 0.1469 - val_mean_absolute_error: 0.2238\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.0258 - mean_absolute_error: 0.1200 - val_loss: 0.1394 - val_mean_absolute_error: 0.2191\n",
      "Epoch 48/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0258 - mean_absolute_error: 0.1204 - val_loss: 0.1410 - val_mean_absolute_error: 0.2183\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 980us/step - loss: 0.0276 - mean_absolute_error: 0.1239 - val_loss: 0.1419 - val_mean_absolute_error: 0.2194\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 970us/step - loss: 0.0298 - mean_absolute_error: 0.1255 - val_loss: 0.1412 - val_mean_absolute_error: 0.2201\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.0310 - mean_absolute_error: 0.1272 - val_loss: 0.1471 - val_mean_absolute_error: 0.2279\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0263 - mean_absolute_error: 0.1201 - val_loss: 0.1464 - val_mean_absolute_error: 0.2249\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 773us/step - loss: 0.0275 - mean_absolute_error: 0.1228 - val_loss: 0.1439 - val_mean_absolute_error: 0.2214\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0274 - mean_absolute_error: 0.1223 - val_loss: 0.1425 - val_mean_absolute_error: 0.2211\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0264 - mean_absolute_error: 0.1206 - val_loss: 0.1445 - val_mean_absolute_error: 0.2202\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0272 - mean_absolute_error: 0.1228 - val_loss: 0.1438 - val_mean_absolute_error: 0.2186\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0249 - mean_absolute_error: 0.1179 - val_loss: 0.1405 - val_mean_absolute_error: 0.2201\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0253 - mean_absolute_error: 0.1184 - val_loss: 0.1412 - val_mean_absolute_error: 0.2215\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0258 - mean_absolute_error: 0.1196 - val_loss: 0.1470 - val_mean_absolute_error: 0.2250\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0267 - mean_absolute_error: 0.1209 - val_loss: 0.1593 - val_mean_absolute_error: 0.2250\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 932us/step - loss: 0.0289 - mean_absolute_error: 0.1253 - val_loss: 0.1455 - val_mean_absolute_error: 0.2193\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 914us/step - loss: 0.0290 - mean_absolute_error: 0.1245 - val_loss: 0.1379 - val_mean_absolute_error: 0.2181\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0264 - mean_absolute_error: 0.1198 - val_loss: 0.1470 - val_mean_absolute_error: 0.2225\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0286 - mean_absolute_error: 0.1239 - val_loss: 0.1428 - val_mean_absolute_error: 0.2199\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0259 - mean_absolute_error: 0.1200 - val_loss: 0.1398 - val_mean_absolute_error: 0.2201\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.0292 - mean_absolute_error: 0.1254 - val_loss: 0.1459 - val_mean_absolute_error: 0.2219\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0321 - mean_absolute_error: 0.1280 - val_loss: 0.1381 - val_mean_absolute_error: 0.2177\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 704us/step - loss: 0.0259 - mean_absolute_error: 0.1196 - val_loss: 0.1419 - val_mean_absolute_error: 0.2194\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 854us/step - loss: 0.0257 - mean_absolute_error: 0.1186 - val_loss: 0.1426 - val_mean_absolute_error: 0.2209\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0269 - mean_absolute_error: 0.1212 - val_loss: 0.1422 - val_mean_absolute_error: 0.2199\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0279 - mean_absolute_error: 0.1223 - val_loss: 0.1431 - val_mean_absolute_error: 0.2269\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0254 - mean_absolute_error: 0.1187 - val_loss: 0.1403 - val_mean_absolute_error: 0.2190\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0255 - mean_absolute_error: 0.1185 - val_loss: 0.1418 - val_mean_absolute_error: 0.2194\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0260 - mean_absolute_error: 0.1199 - val_loss: 0.1389 - val_mean_absolute_error: 0.2188\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0255 - mean_absolute_error: 0.1184 - val_loss: 0.1438 - val_mean_absolute_error: 0.2205\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0247 - mean_absolute_error: 0.1175 - val_loss: 0.1461 - val_mean_absolute_error: 0.2227\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 735us/step - loss: 0.0253 - mean_absolute_error: 0.1194 - val_loss: 0.1470 - val_mean_absolute_error: 0.2233\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 868us/step - loss: 0.0281 - mean_absolute_error: 0.1235 - val_loss: 0.1467 - val_mean_absolute_error: 0.2265\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0269 - mean_absolute_error: 0.1205 - val_loss: 0.1428 - val_mean_absolute_error: 0.2204\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0262 - mean_absolute_error: 0.1192 - val_loss: 0.1467 - val_mean_absolute_error: 0.2235\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0260 - mean_absolute_error: 0.1195 - val_loss: 0.1444 - val_mean_absolute_error: 0.2213\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0264 - mean_absolute_error: 0.1213 - val_loss: 0.1439 - val_mean_absolute_error: 0.2201\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0270 - mean_absolute_error: 0.1203 - val_loss: 0.1535 - val_mean_absolute_error: 0.2389\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0315 - mean_absolute_error: 0.1273 - val_loss: 0.1427 - val_mean_absolute_error: 0.2181\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0276 - mean_absolute_error: 0.1209 - val_loss: 0.1500 - val_mean_absolute_error: 0.2232\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0248 - mean_absolute_error: 0.1182 - val_loss: 0.1406 - val_mean_absolute_error: 0.2205\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0233 - mean_absolute_error: 0.1146 - val_loss: 0.1419 - val_mean_absolute_error: 0.2188\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0244 - mean_absolute_error: 0.1161 - val_loss: 0.1448 - val_mean_absolute_error: 0.2216\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0241 - mean_absolute_error: 0.1162 - val_loss: 0.1428 - val_mean_absolute_error: 0.2201\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0241 - mean_absolute_error: 0.1160 - val_loss: 0.1465 - val_mean_absolute_error: 0.2217\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 856us/step - loss: 0.0311 - mean_absolute_error: 0.1263 - val_loss: 0.1454 - val_mean_absolute_error: 0.2252\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0346 - mean_absolute_error: 0.1317 - val_loss: 0.1460 - val_mean_absolute_error: 0.2260\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 924us/step - loss: 0.0283 - mean_absolute_error: 0.1237 - val_loss: 0.1471 - val_mean_absolute_error: 0.2253\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0248 - mean_absolute_error: 0.1173 - val_loss: 0.1427 - val_mean_absolute_error: 0.2216\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 920us/step - loss: 0.0233 - mean_absolute_error: 0.1141 - val_loss: 0.1433 - val_mean_absolute_error: 0.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0232 - mean_absolute_error: 0.1140 - val_loss: 0.1424 - val_mean_absolute_error: 0.2209\n",
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.0237 - mean_absolute_error: 0.1154 - val_loss: 0.1455 - val_mean_absolute_error: 0.2215\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 826us/step - loss: 0.0260 - mean_absolute_error: 0.1197 - val_loss: 0.1433 - val_mean_absolute_error: 0.2240\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0248 - mean_absolute_error: 0.1178 - val_loss: 0.1441 - val_mean_absolute_error: 0.2205\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 854us/step - loss: 0.0235 - mean_absolute_error: 0.1151 - val_loss: 0.1466 - val_mean_absolute_error: 0.2250\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0250 - mean_absolute_error: 0.1184 - val_loss: 0.1465 - val_mean_absolute_error: 0.2281\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0284 - mean_absolute_error: 0.1231 - val_loss: 0.1461 - val_mean_absolute_error: 0.2291\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0265 - mean_absolute_error: 0.1205 - val_loss: 0.1420 - val_mean_absolute_error: 0.2224\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0259 - mean_absolute_error: 0.1200 - val_loss: 0.1460 - val_mean_absolute_error: 0.2239\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0242 - mean_absolute_error: 0.1161 - val_loss: 0.1437 - val_mean_absolute_error: 0.2210\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0238 - mean_absolute_error: 0.1153 - val_loss: 0.1451 - val_mean_absolute_error: 0.2260\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_absolute_error: 0.1168 - val_loss: 0.1541 - val_mean_absolute_error: 0.2263\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0245 - mean_absolute_error: 0.1168 - val_loss: 0.1453 - val_mean_absolute_error: 0.2226\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0276 - mean_absolute_error: 0.1216 - val_loss: 0.1459 - val_mean_absolute_error: 0.2210\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0258 - mean_absolute_error: 0.1189 - val_loss: 0.1438 - val_mean_absolute_error: 0.2209\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0248 - mean_absolute_error: 0.1176 - val_loss: 0.1442 - val_mean_absolute_error: 0.2233\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0249 - mean_absolute_error: 0.1178 - val_loss: 0.1489 - val_mean_absolute_error: 0.2310\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 887us/step - loss: 0.0241 - mean_absolute_error: 0.1158 - val_loss: 0.1455 - val_mean_absolute_error: 0.2254\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0256 - mean_absolute_error: 0.1185 - val_loss: 0.1464 - val_mean_absolute_error: 0.2233\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0252 - mean_absolute_error: 0.1181 - val_loss: 0.1538 - val_mean_absolute_error: 0.2275\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0285 - mean_absolute_error: 0.1223 - val_loss: 0.1488 - val_mean_absolute_error: 0.2236\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0284 - mean_absolute_error: 0.1238 - val_loss: 0.1449 - val_mean_absolute_error: 0.2218\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0256 - mean_absolute_error: 0.1183 - val_loss: 0.1424 - val_mean_absolute_error: 0.2212\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0279 - mean_absolute_error: 0.1209 - val_loss: 0.1457 - val_mean_absolute_error: 0.2230\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0260 - mean_absolute_error: 0.1186 - val_loss: 0.1479 - val_mean_absolute_error: 0.2235\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0242 - mean_absolute_error: 0.1161 - val_loss: 0.1494 - val_mean_absolute_error: 0.2234\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0248 - mean_absolute_error: 0.1173 - val_loss: 0.1488 - val_mean_absolute_error: 0.2244\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0231 - mean_absolute_error: 0.1144 - val_loss: 0.1458 - val_mean_absolute_error: 0.2215\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0233 - mean_absolute_error: 0.1143 - val_loss: 0.1465 - val_mean_absolute_error: 0.2239\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0245 - mean_absolute_error: 0.1165 - val_loss: 0.1462 - val_mean_absolute_error: 0.2220\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0257 - mean_absolute_error: 0.1193 - val_loss: 0.1465 - val_mean_absolute_error: 0.2293\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0254 - mean_absolute_error: 0.1185 - val_loss: 0.1506 - val_mean_absolute_error: 0.2243\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0270 - mean_absolute_error: 0.1203 - val_loss: 0.1467 - val_mean_absolute_error: 0.2239\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0247 - mean_absolute_error: 0.1165 - val_loss: 0.1444 - val_mean_absolute_error: 0.2260\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0259 - mean_absolute_error: 0.1186 - val_loss: 0.1435 - val_mean_absolute_error: 0.2218\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0257 - mean_absolute_error: 0.1184 - val_loss: 0.1477 - val_mean_absolute_error: 0.2251\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0252 - mean_absolute_error: 0.1178 - val_loss: 0.1425 - val_mean_absolute_error: 0.2237\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0235 - mean_absolute_error: 0.1154 - val_loss: 0.1471 - val_mean_absolute_error: 0.2242\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0237 - mean_absolute_error: 0.1151 - val_loss: 0.1472 - val_mean_absolute_error: 0.2252\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0261 - mean_absolute_error: 0.1208 - val_loss: 0.1459 - val_mean_absolute_error: 0.2230\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.0237 - mean_absolute_error: 0.1146 - val_loss: 0.1479 - val_mean_absolute_error: 0.2230\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0238 - mean_absolute_error: 0.1150 - val_loss: 0.1486 - val_mean_absolute_error: 0.2239\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0228 - mean_absolute_error: 0.1132 - val_loss: 0.1479 - val_mean_absolute_error: 0.2241\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0234 - mean_absolute_error: 0.1152 - val_loss: 0.1469 - val_mean_absolute_error: 0.2231\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0245 - mean_absolute_error: 0.1176 - val_loss: 0.1515 - val_mean_absolute_error: 0.2355\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0272 - mean_absolute_error: 0.1213 - val_loss: 0.1471 - val_mean_absolute_error: 0.2258\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0251 - mean_absolute_error: 0.1178 - val_loss: 0.1478 - val_mean_absolute_error: 0.2240\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0264 - mean_absolute_error: 0.1185 - val_loss: 0.1478 - val_mean_absolute_error: 0.2285\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 872us/step - loss: 0.0281 - mean_absolute_error: 0.1212 - val_loss: 0.1459 - val_mean_absolute_error: 0.2222\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0291 - mean_absolute_error: 0.1237 - val_loss: 0.1431 - val_mean_absolute_error: 0.2224\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0237 - mean_absolute_error: 0.1153 - val_loss: 0.1470 - val_mean_absolute_error: 0.2224\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 894us/step - loss: 0.0238 - mean_absolute_error: 0.1156 - val_loss: 0.1464 - val_mean_absolute_error: 0.2231\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 879us/step - loss: 0.0229 - mean_absolute_error: 0.1133 - val_loss: 0.1508 - val_mean_absolute_error: 0.2291\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 932us/step - loss: 0.0229 - mean_absolute_error: 0.1134 - val_loss: 0.1498 - val_mean_absolute_error: 0.2244\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 915us/step - loss: 0.0232 - mean_absolute_error: 0.1140 - val_loss: 0.1451 - val_mean_absolute_error: 0.2215\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0223 - mean_absolute_error: 0.1124 - val_loss: 0.1485 - val_mean_absolute_error: 0.2266\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 949us/step - loss: 0.0230 - mean_absolute_error: 0.1142 - val_loss: 0.1448 - val_mean_absolute_error: 0.2217\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 778us/step - loss: 0.0237 - mean_absolute_error: 0.1155 - val_loss: 0.1502 - val_mean_absolute_error: 0.2288\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0262 - mean_absolute_error: 0.1198 - val_loss: 0.1456 - val_mean_absolute_error: 0.2248\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0259 - mean_absolute_error: 0.1192 - val_loss: 0.1513 - val_mean_absolute_error: 0.2265\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0293 - mean_absolute_error: 0.1237 - val_loss: 0.1474 - val_mean_absolute_error: 0.2243\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 761us/step - loss: 0.0271 - mean_absolute_error: 0.1215 - val_loss: 0.1442 - val_mean_absolute_error: 0.2246\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0246 - mean_absolute_error: 0.1157 - val_loss: 0.1452 - val_mean_absolute_error: 0.2239\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0238 - mean_absolute_error: 0.1149 - val_loss: 0.1466 - val_mean_absolute_error: 0.2262\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0239 - mean_absolute_error: 0.1156 - val_loss: 0.1495 - val_mean_absolute_error: 0.2257\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0235 - mean_absolute_error: 0.1146 - val_loss: 0.1472 - val_mean_absolute_error: 0.2231\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0225 - mean_absolute_error: 0.1129 - val_loss: 0.1452 - val_mean_absolute_error: 0.2224\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0232 - mean_absolute_error: 0.1138 - val_loss: 0.1457 - val_mean_absolute_error: 0.2243\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0232 - mean_absolute_error: 0.1152 - val_loss: 0.1474 - val_mean_absolute_error: 0.2236\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 776us/step - loss: 0.0245 - mean_absolute_error: 0.1168 - val_loss: 0.1472 - val_mean_absolute_error: 0.2264\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0269 - mean_absolute_error: 0.1200 - val_loss: 0.1494 - val_mean_absolute_error: 0.2289\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 864us/step - loss: 0.0258 - mean_absolute_error: 0.1189 - val_loss: 0.1459 - val_mean_absolute_error: 0.2218\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 851us/step - loss: 0.0226 - mean_absolute_error: 0.1127 - val_loss: 0.1532 - val_mean_absolute_error: 0.2290\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 968us/step - loss: 0.0241 - mean_absolute_error: 0.1160 - val_loss: 0.1483 - val_mean_absolute_error: 0.2241\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0229 - mean_absolute_error: 0.1138 - val_loss: 0.1442 - val_mean_absolute_error: 0.2238\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0233 - mean_absolute_error: 0.1149 - val_loss: 0.1468 - val_mean_absolute_error: 0.2225\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0236 - mean_absolute_error: 0.1144 - val_loss: 0.1525 - val_mean_absolute_error: 0.2279\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 887us/step - loss: 0.0229 - mean_absolute_error: 0.1144 - val_loss: 0.1502 - val_mean_absolute_error: 0.2302\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 773us/step - loss: 0.0243 - mean_absolute_error: 0.1163 - val_loss: 0.1475 - val_mean_absolute_error: 0.2273\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0263 - mean_absolute_error: 0.1203 - val_loss: 0.1478 - val_mean_absolute_error: 0.2287\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0265 - mean_absolute_error: 0.1195 - val_loss: 0.1471 - val_mean_absolute_error: 0.2241\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0258 - mean_absolute_error: 0.1176 - val_loss: 0.1474 - val_mean_absolute_error: 0.2233\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0227 - mean_absolute_error: 0.1121 - val_loss: 0.1532 - val_mean_absolute_error: 0.2351\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0254 - mean_absolute_error: 0.1180 - val_loss: 0.1471 - val_mean_absolute_error: 0.2258\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 885us/step - loss: 0.0229 - mean_absolute_error: 0.1137 - val_loss: 0.1464 - val_mean_absolute_error: 0.2243\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0233 - mean_absolute_error: 0.1140 - val_loss: 0.1493 - val_mean_absolute_error: 0.2278\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 867us/step - loss: 0.0235 - mean_absolute_error: 0.1146 - val_loss: 0.1503 - val_mean_absolute_error: 0.2294\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0234 - mean_absolute_error: 0.1142 - val_loss: 0.1481 - val_mean_absolute_error: 0.2248\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0240 - mean_absolute_error: 0.1162 - val_loss: 0.1464 - val_mean_absolute_error: 0.2241\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0231 - mean_absolute_error: 0.1142 - val_loss: 0.1456 - val_mean_absolute_error: 0.2249\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0228 - mean_absolute_error: 0.1133 - val_loss: 0.1470 - val_mean_absolute_error: 0.2275\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.0236 - mean_absolute_error: 0.1151 - val_loss: 0.1522 - val_mean_absolute_error: 0.2287\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0247 - mean_absolute_error: 0.1165 - val_loss: 0.1521 - val_mean_absolute_error: 0.2265\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0272 - mean_absolute_error: 0.1207 - val_loss: 0.1486 - val_mean_absolute_error: 0.2242\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0248 - mean_absolute_error: 0.1155 - val_loss: 0.1455 - val_mean_absolute_error: 0.2240\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0247 - mean_absolute_error: 0.1166 - val_loss: 0.1483 - val_mean_absolute_error: 0.2261\n",
      "Epoch 192/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 898us/step - loss: 0.0254 - mean_absolute_error: 0.1170 - val_loss: 0.1484 - val_mean_absolute_error: 0.2264\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 0s 937us/step - loss: 0.0238 - mean_absolute_error: 0.1140 - val_loss: 0.1455 - val_mean_absolute_error: 0.2270\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 853us/step - loss: 0.0233 - mean_absolute_error: 0.1147 - val_loss: 0.1459 - val_mean_absolute_error: 0.2247\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0221 - mean_absolute_error: 0.1109 - val_loss: 0.1459 - val_mean_absolute_error: 0.2264\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 897us/step - loss: 0.0223 - mean_absolute_error: 0.1121 - val_loss: 0.1465 - val_mean_absolute_error: 0.2242\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 985us/step - loss: 0.0224 - mean_absolute_error: 0.1123 - val_loss: 0.1471 - val_mean_absolute_error: 0.2257\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0240 - mean_absolute_error: 0.1150 - val_loss: 0.1449 - val_mean_absolute_error: 0.2228\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0238 - mean_absolute_error: 0.1157 - val_loss: 0.1474 - val_mean_absolute_error: 0.2266\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0229 - mean_absolute_error: 0.1129 - val_loss: 0.1487 - val_mean_absolute_error: 0.2254\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0240 - mean_absolute_error: 0.1152 - val_loss: 0.1463 - val_mean_absolute_error: 0.2248\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 841us/step - loss: 0.0230 - mean_absolute_error: 0.1136 - val_loss: 0.1547 - val_mean_absolute_error: 0.2259\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 834us/step - loss: 0.0245 - mean_absolute_error: 0.1157 - val_loss: 0.1535 - val_mean_absolute_error: 0.2293\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 938us/step - loss: 0.0287 - mean_absolute_error: 0.1223 - val_loss: 0.1516 - val_mean_absolute_error: 0.2261\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 846us/step - loss: 0.0240 - mean_absolute_error: 0.1150 - val_loss: 0.1464 - val_mean_absolute_error: 0.2247\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0221 - mean_absolute_error: 0.1121 - val_loss: 0.1518 - val_mean_absolute_error: 0.2258\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 841us/step - loss: 0.0219 - mean_absolute_error: 0.1112 - val_loss: 0.1517 - val_mean_absolute_error: 0.2266\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 841us/step - loss: 0.0231 - mean_absolute_error: 0.1131 - val_loss: 0.1486 - val_mean_absolute_error: 0.2270\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0223 - mean_absolute_error: 0.1119 - val_loss: 0.1465 - val_mean_absolute_error: 0.2267\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0217 - mean_absolute_error: 0.1108 - val_loss: 0.1542 - val_mean_absolute_error: 0.2317\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0219 - mean_absolute_error: 0.1116 - val_loss: 0.1454 - val_mean_absolute_error: 0.2240\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0231 - mean_absolute_error: 0.1136 - val_loss: 0.1491 - val_mean_absolute_error: 0.2250\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 863us/step - loss: 0.0235 - mean_absolute_error: 0.1149 - val_loss: 0.1504 - val_mean_absolute_error: 0.2257\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 977us/step - loss: 0.0230 - mean_absolute_error: 0.1136 - val_loss: 0.1467 - val_mean_absolute_error: 0.2248\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 846us/step - loss: 0.0228 - mean_absolute_error: 0.1126 - val_loss: 0.1481 - val_mean_absolute_error: 0.2260\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 988us/step - loss: 0.0219 - mean_absolute_error: 0.1115 - val_loss: 0.1478 - val_mean_absolute_error: 0.2262\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 918us/step - loss: 0.0226 - mean_absolute_error: 0.1132 - val_loss: 0.1514 - val_mean_absolute_error: 0.2289\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0233 - mean_absolute_error: 0.1140 - val_loss: 0.1521 - val_mean_absolute_error: 0.2304\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0247 - mean_absolute_error: 0.1167 - val_loss: 0.1488 - val_mean_absolute_error: 0.2261\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0253 - mean_absolute_error: 0.1175 - val_loss: 0.1442 - val_mean_absolute_error: 0.2263\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.0235 - mean_absolute_error: 0.1144 - val_loss: 0.1468 - val_mean_absolute_error: 0.2240\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.0227 - mean_absolute_error: 0.1127 - val_loss: 0.1431 - val_mean_absolute_error: 0.2237\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0232 - mean_absolute_error: 0.1145 - val_loss: 0.1460 - val_mean_absolute_error: 0.2257\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 840us/step - loss: 0.0227 - mean_absolute_error: 0.1133 - val_loss: 0.1460 - val_mean_absolute_error: 0.2250\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 834us/step - loss: 0.0251 - mean_absolute_error: 0.1169 - val_loss: 0.1536 - val_mean_absolute_error: 0.2284\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0284 - mean_absolute_error: 0.1227 - val_loss: 0.1499 - val_mean_absolute_error: 0.2281\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 976us/step - loss: 0.0230 - mean_absolute_error: 0.1129 - val_loss: 0.1508 - val_mean_absolute_error: 0.2272\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 922us/step - loss: 0.0228 - mean_absolute_error: 0.1129 - val_loss: 0.1523 - val_mean_absolute_error: 0.2282\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 909us/step - loss: 0.0211 - mean_absolute_error: 0.1093 - val_loss: 0.1515 - val_mean_absolute_error: 0.2282\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0223 - mean_absolute_error: 0.1114 - val_loss: 0.1477 - val_mean_absolute_error: 0.2275\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0231 - mean_absolute_error: 0.1137 - val_loss: 0.1441 - val_mean_absolute_error: 0.2265\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 872us/step - loss: 0.0270 - mean_absolute_error: 0.1183 - val_loss: 0.1506 - val_mean_absolute_error: 0.2272\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0218 - mean_absolute_error: 0.1105 - val_loss: 0.1495 - val_mean_absolute_error: 0.2290\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0233 - mean_absolute_error: 0.1135 - val_loss: 0.1470 - val_mean_absolute_error: 0.2284\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0213 - mean_absolute_error: 0.1102 - val_loss: 0.1510 - val_mean_absolute_error: 0.2263\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0210 - mean_absolute_error: 0.1098 - val_loss: 0.1443 - val_mean_absolute_error: 0.2233\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 819us/step - loss: 0.0216 - mean_absolute_error: 0.1106 - val_loss: 0.1521 - val_mean_absolute_error: 0.2289\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0225 - mean_absolute_error: 0.1124 - val_loss: 0.1457 - val_mean_absolute_error: 0.2252\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0225 - mean_absolute_error: 0.1134 - val_loss: 0.1460 - val_mean_absolute_error: 0.2248\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 930us/step - loss: 0.0229 - mean_absolute_error: 0.1139 - val_loss: 0.1425 - val_mean_absolute_error: 0.2227\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0227 - mean_absolute_error: 0.1138 - val_loss: 0.1506 - val_mean_absolute_error: 0.2267\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0236 - mean_absolute_error: 0.1147 - val_loss: 0.1460 - val_mean_absolute_error: 0.2281\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0230 - mean_absolute_error: 0.1136 - val_loss: 0.1478 - val_mean_absolute_error: 0.2242\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0225 - mean_absolute_error: 0.1125 - val_loss: 0.1461 - val_mean_absolute_error: 0.2240\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0227 - mean_absolute_error: 0.1129 - val_loss: 0.1517 - val_mean_absolute_error: 0.2274\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0253 - mean_absolute_error: 0.1175 - val_loss: 0.1504 - val_mean_absolute_error: 0.2273\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0243 - mean_absolute_error: 0.1148 - val_loss: 0.1472 - val_mean_absolute_error: 0.2247\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 890us/step - loss: 0.0214 - mean_absolute_error: 0.1101 - val_loss: 0.1524 - val_mean_absolute_error: 0.2297\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 819us/step - loss: 0.0209 - mean_absolute_error: 0.1085 - val_loss: 0.1527 - val_mean_absolute_error: 0.2314\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 841us/step - loss: 0.0226 - mean_absolute_error: 0.1122 - val_loss: 0.1501 - val_mean_absolute_error: 0.2275\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 977us/step - loss: 0.0255 - mean_absolute_error: 0.1163 - val_loss: 0.1479 - val_mean_absolute_error: 0.2257\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0246 - mean_absolute_error: 0.1164 - val_loss: 0.1443 - val_mean_absolute_error: 0.2240\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0227 - mean_absolute_error: 0.1125 - val_loss: 0.1500 - val_mean_absolute_error: 0.2281\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0269 - mean_absolute_error: 0.1187 - val_loss: 0.1502 - val_mean_absolute_error: 0.2259\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0234 - mean_absolute_error: 0.1142 - val_loss: 0.1445 - val_mean_absolute_error: 0.2237\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0220 - mean_absolute_error: 0.1106 - val_loss: 0.1471 - val_mean_absolute_error: 0.2256\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0214 - mean_absolute_error: 0.1100 - val_loss: 0.1495 - val_mean_absolute_error: 0.2275\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0208 - mean_absolute_error: 0.1086 - val_loss: 0.1495 - val_mean_absolute_error: 0.2290\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0214 - mean_absolute_error: 0.1102 - val_loss: 0.1468 - val_mean_absolute_error: 0.2283\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0228 - mean_absolute_error: 0.1132 - val_loss: 0.1479 - val_mean_absolute_error: 0.2256\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0215 - mean_absolute_error: 0.1103 - val_loss: 0.1505 - val_mean_absolute_error: 0.2266\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0216 - mean_absolute_error: 0.1106 - val_loss: 0.1492 - val_mean_absolute_error: 0.2285\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.0223 - mean_absolute_error: 0.1121 - val_loss: 0.1559 - val_mean_absolute_error: 0.2306\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0227 - mean_absolute_error: 0.1124 - val_loss: 0.1497 - val_mean_absolute_error: 0.2248\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0248 - mean_absolute_error: 0.1157 - val_loss: 0.1481 - val_mean_absolute_error: 0.2265\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0261 - mean_absolute_error: 0.1179 - val_loss: 0.1593 - val_mean_absolute_error: 0.2336\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0244 - mean_absolute_error: 0.1159 - val_loss: 0.1522 - val_mean_absolute_error: 0.2291\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0228 - mean_absolute_error: 0.1123 - val_loss: 0.1433 - val_mean_absolute_error: 0.2303\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0220 - mean_absolute_error: 0.1117 - val_loss: 0.1507 - val_mean_absolute_error: 0.2271\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0217 - mean_absolute_error: 0.1106 - val_loss: 0.1489 - val_mean_absolute_error: 0.2260\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0216 - mean_absolute_error: 0.1099 - val_loss: 0.1462 - val_mean_absolute_error: 0.2251\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0220 - mean_absolute_error: 0.1113 - val_loss: 0.1540 - val_mean_absolute_error: 0.2290\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0213 - mean_absolute_error: 0.1102 - val_loss: 0.1478 - val_mean_absolute_error: 0.2258\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0221 - mean_absolute_error: 0.1116 - val_loss: 0.1499 - val_mean_absolute_error: 0.2277\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0225 - mean_absolute_error: 0.1116 - val_loss: 0.1512 - val_mean_absolute_error: 0.2276\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0252 - mean_absolute_error: 0.1169 - val_loss: 0.1489 - val_mean_absolute_error: 0.2261\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0235 - mean_absolute_error: 0.1149 - val_loss: 0.1482 - val_mean_absolute_error: 0.2269\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0211 - mean_absolute_error: 0.1094 - val_loss: 0.1484 - val_mean_absolute_error: 0.2261\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0219 - mean_absolute_error: 0.1110 - val_loss: 0.1497 - val_mean_absolute_error: 0.2269\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0238 - mean_absolute_error: 0.1154 - val_loss: 0.1482 - val_mean_absolute_error: 0.2277\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 851us/step - loss: 0.0220 - mean_absolute_error: 0.1114 - val_loss: 0.1497 - val_mean_absolute_error: 0.2271\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0220 - mean_absolute_error: 0.1116 - val_loss: 0.1496 - val_mean_absolute_error: 0.2301\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0222 - mean_absolute_error: 0.1111 - val_loss: 0.1520 - val_mean_absolute_error: 0.2271\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 811us/step - loss: 0.0241 - mean_absolute_error: 0.1155 - val_loss: 0.1495 - val_mean_absolute_error: 0.2300\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0237 - mean_absolute_error: 0.1138 - val_loss: 0.1549 - val_mean_absolute_error: 0.2313\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0284 - mean_absolute_error: 0.1206 - val_loss: 0.1479 - val_mean_absolute_error: 0.2257\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0235 - mean_absolute_error: 0.1127 - val_loss: 0.1485 - val_mean_absolute_error: 0.2249\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 886us/step - loss: 0.0220 - mean_absolute_error: 0.1112 - val_loss: 0.1448 - val_mean_absolute_error: 0.2259\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0214 - mean_absolute_error: 0.1098 - val_loss: 0.1546 - val_mean_absolute_error: 0.2377\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0204 - mean_absolute_error: 0.1079 - val_loss: 0.1482 - val_mean_absolute_error: 0.2262\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 873us/step - loss: 0.0205 - mean_absolute_error: 0.1082 - val_loss: 0.1510 - val_mean_absolute_error: 0.2284\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0207 - mean_absolute_error: 0.1087 - val_loss: 0.1516 - val_mean_absolute_error: 0.2279\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0215 - mean_absolute_error: 0.1097 - val_loss: 0.1504 - val_mean_absolute_error: 0.2275\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 936us/step - loss: 0.0252 - mean_absolute_error: 0.1162 - val_loss: 0.1508 - val_mean_absolute_error: 0.2283\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 951us/step - loss: 0.0233 - mean_absolute_error: 0.1140 - val_loss: 0.1538 - val_mean_absolute_error: 0.2306\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 867us/step - loss: 0.0245 - mean_absolute_error: 0.1155 - val_loss: 0.1454 - val_mean_absolute_error: 0.2256\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0231 - mean_absolute_error: 0.1128 - val_loss: 0.1572 - val_mean_absolute_error: 0.2379\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0228 - mean_absolute_error: 0.1124 - val_loss: 0.1489 - val_mean_absolute_error: 0.2266\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0238 - mean_absolute_error: 0.1136 - val_loss: 0.1481 - val_mean_absolute_error: 0.2257\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0219 - mean_absolute_error: 0.1100 - val_loss: 0.1496 - val_mean_absolute_error: 0.2262\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,  # training data\n",
    "               batch_size=64,  # Batch size is set to 64\n",
    "               epochs=300,  # Train the entire dataset 300 times\n",
    "               validation_data=(x_val, y_val),  # Verification information\n",
    "               callbacks=[model_cbk, model_mckp]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()  # View what information is saved in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2330d756dc0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylim(0.02, 0.2)\n",
    "plt.title('Mean square error')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2330da43640>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'], label='train')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
    "plt.ylim(0.12, 0.26)\n",
    "plt.title('Mean absolute error')\n",
    "plt.ylabel('metrics')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average percentage error on test data\n",
    "\n",
    "Predict house price on test data and calculate the average percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Percentage Error: 13.94%\n"
     ]
    }
   ],
   "source": [
    "# #Load model\n",
    "model = keras.models.load_model('lab2-logs/models/Best-model-1.h5')\n",
    "# take out the house price\n",
    "y_test = np.array(test_data['price'])\n",
    "# data normalization\n",
    "test_data = (test_data - mean) / std\n",
    "# Save the input data in Numpy format\n",
    "x_test = np.array(test_data.drop('price', axis='columns'))\n",
    "# Predict on test data\n",
    "y_pred = model.predict(x_test)\n",
    "# Convert the prediction results back \n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "# Calculate the mean percentage error\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "# Display percentage error\n",
    "print(\"Model_1 Percentage Error: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# display TensorBoard directly on the jupyter notebook\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 9530 (pid 9028), started 0:08:01 ago. (Use '!kill 9028' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-166de6e9300e8299\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-166de6e9300e8299\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 9530;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port 9530 --logdir lab2-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Overfitting Problem\n",
    "\n",
    "### 1.\tModel-2: model of reducing the model-1 size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 41s - loss: 0.6996 - mean_absolute_error: 0.5855WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_begin` time: 0.0120s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.3988s). Check your callbacks.\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.4557 - mean_absolute_error: 0.4348 - val_loss: 0.2867 - val_mean_absolute_error: 0.3488\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.2648 - mean_absolute_error: 0.3278 - val_loss: 0.2311 - val_mean_absolute_error: 0.3091\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.2358 - mean_absolute_error: 0.3068 - val_loss: 0.2132 - val_mean_absolute_error: 0.2974\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.2185 - mean_absolute_error: 0.2926 - val_loss: 0.1982 - val_mean_absolute_error: 0.2813\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 955us/step - loss: 0.2060 - mean_absolute_error: 0.2833 - val_loss: 0.1896 - val_mean_absolute_error: 0.2765\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.1966 - mean_absolute_error: 0.2759 - val_loss: 0.1855 - val_mean_absolute_error: 0.2743\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.1865 - mean_absolute_error: 0.2695 - val_loss: 0.1739 - val_mean_absolute_error: 0.2640\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.1797 - mean_absolute_error: 0.2642 - val_loss: 0.1679 - val_mean_absolute_error: 0.2574\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.1715 - mean_absolute_error: 0.2577 - val_loss: 0.1644 - val_mean_absolute_error: 0.2554\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.1650 - mean_absolute_error: 0.2512 - val_loss: 0.1560 - val_mean_absolute_error: 0.2497\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.1593 - mean_absolute_error: 0.2464 - val_loss: 0.1545 - val_mean_absolute_error: 0.2468\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1543 - mean_absolute_error: 0.2418 - val_loss: 0.1489 - val_mean_absolute_error: 0.2435\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 936us/step - loss: 0.1504 - mean_absolute_error: 0.2399 - val_loss: 0.1472 - val_mean_absolute_error: 0.2400\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.1444 - mean_absolute_error: 0.2345 - val_loss: 0.1448 - val_mean_absolute_error: 0.2381\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.1420 - mean_absolute_error: 0.2324 - val_loss: 0.1406 - val_mean_absolute_error: 0.2346\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.1378 - mean_absolute_error: 0.2293 - val_loss: 0.1446 - val_mean_absolute_error: 0.2414\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.1338 - mean_absolute_error: 0.2251 - val_loss: 0.1350 - val_mean_absolute_error: 0.2289\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.1315 - mean_absolute_error: 0.2240 - val_loss: 0.1354 - val_mean_absolute_error: 0.2302\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 935us/step - loss: 0.1295 - mean_absolute_error: 0.2216 - val_loss: 0.1328 - val_mean_absolute_error: 0.2242\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.1250 - mean_absolute_error: 0.2180 - val_loss: 0.1356 - val_mean_absolute_error: 0.2280\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1231 - mean_absolute_error: 0.2168 - val_loss: 0.1293 - val_mean_absolute_error: 0.2199\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1224 - mean_absolute_error: 0.2151 - val_loss: 0.1290 - val_mean_absolute_error: 0.2200\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.1193 - mean_absolute_error: 0.2126 - val_loss: 0.1292 - val_mean_absolute_error: 0.2200\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1178 - mean_absolute_error: 0.2123 - val_loss: 0.1294 - val_mean_absolute_error: 0.2208\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1173 - mean_absolute_error: 0.2121 - val_loss: 0.1285 - val_mean_absolute_error: 0.2186\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1140 - mean_absolute_error: 0.2096 - val_loss: 0.1292 - val_mean_absolute_error: 0.2175\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.1151 - mean_absolute_error: 0.2088 - val_loss: 0.1260 - val_mean_absolute_error: 0.2161\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.1126 - mean_absolute_error: 0.2064 - val_loss: 0.1240 - val_mean_absolute_error: 0.2159\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.1101 - mean_absolute_error: 0.2061 - val_loss: 0.1223 - val_mean_absolute_error: 0.2126\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.1087 - mean_absolute_error: 0.2049 - val_loss: 0.1270 - val_mean_absolute_error: 0.2166\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.1089 - mean_absolute_error: 0.2049 - val_loss: 0.1229 - val_mean_absolute_error: 0.2129\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.1055 - mean_absolute_error: 0.2025 - val_loss: 0.1236 - val_mean_absolute_error: 0.2123\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.1066 - mean_absolute_error: 0.2027 - val_loss: 0.1251 - val_mean_absolute_error: 0.2146\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.1054 - mean_absolute_error: 0.2011 - val_loss: 0.1223 - val_mean_absolute_error: 0.2107\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.1051 - mean_absolute_error: 0.2008 - val_loss: 0.1231 - val_mean_absolute_error: 0.2106\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.1030 - mean_absolute_error: 0.2001 - val_loss: 0.1236 - val_mean_absolute_error: 0.2126\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.1030 - mean_absolute_error: 0.1987 - val_loss: 0.1220 - val_mean_absolute_error: 0.2110\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 795us/step - loss: 0.1015 - mean_absolute_error: 0.1978 - val_loss: 0.1219 - val_mean_absolute_error: 0.2165\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.1009 - mean_absolute_error: 0.1996 - val_loss: 0.1191 - val_mean_absolute_error: 0.2074\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1000 - mean_absolute_error: 0.1973 - val_loss: 0.1217 - val_mean_absolute_error: 0.2089\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0989 - mean_absolute_error: 0.1959 - val_loss: 0.1234 - val_mean_absolute_error: 0.2111\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0997 - mean_absolute_error: 0.1972 - val_loss: 0.1207 - val_mean_absolute_error: 0.2085\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0979 - mean_absolute_error: 0.1965 - val_loss: 0.1167 - val_mean_absolute_error: 0.2074\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0976 - mean_absolute_error: 0.1954 - val_loss: 0.1159 - val_mean_absolute_error: 0.2063\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.0970 - mean_absolute_error: 0.1954 - val_loss: 0.1189 - val_mean_absolute_error: 0.2076\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0954 - mean_absolute_error: 0.1944 - val_loss: 0.1195 - val_mean_absolute_error: 0.2076\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0950 - mean_absolute_error: 0.1941 - val_loss: 0.1200 - val_mean_absolute_error: 0.2085\n",
      "Epoch 48/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0945 - mean_absolute_error: 0.1951 - val_loss: 0.1179 - val_mean_absolute_error: 0.2072\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0952 - mean_absolute_error: 0.1934 - val_loss: 0.1178 - val_mean_absolute_error: 0.2076\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.0940 - mean_absolute_error: 0.1927 - val_loss: 0.1213 - val_mean_absolute_error: 0.2087\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0941 - mean_absolute_error: 0.1930 - val_loss: 0.1148 - val_mean_absolute_error: 0.2080\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0940 - mean_absolute_error: 0.1935 - val_loss: 0.1162 - val_mean_absolute_error: 0.2063\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0924 - mean_absolute_error: 0.1925 - val_loss: 0.1153 - val_mean_absolute_error: 0.2050\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 704us/step - loss: 0.0921 - mean_absolute_error: 0.1920 - val_loss: 0.1185 - val_mean_absolute_error: 0.2085\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.0923 - mean_absolute_error: 0.1916 - val_loss: 0.1170 - val_mean_absolute_error: 0.2059\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0912 - mean_absolute_error: 0.1910 - val_loss: 0.1170 - val_mean_absolute_error: 0.2079\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0904 - mean_absolute_error: 0.1911 - val_loss: 0.1197 - val_mean_absolute_error: 0.2070\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0899 - mean_absolute_error: 0.1895 - val_loss: 0.1212 - val_mean_absolute_error: 0.2107\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0905 - mean_absolute_error: 0.1909 - val_loss: 0.1204 - val_mean_absolute_error: 0.2100\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0899 - mean_absolute_error: 0.1908 - val_loss: 0.1169 - val_mean_absolute_error: 0.2097\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0897 - mean_absolute_error: 0.1912 - val_loss: 0.1144 - val_mean_absolute_error: 0.2058\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0890 - mean_absolute_error: 0.1900 - val_loss: 0.1181 - val_mean_absolute_error: 0.2064\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0889 - mean_absolute_error: 0.1897 - val_loss: 0.1168 - val_mean_absolute_error: 0.2062\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 773us/step - loss: 0.0884 - mean_absolute_error: 0.1890 - val_loss: 0.1197 - val_mean_absolute_error: 0.2085\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 618us/step - loss: 0.0884 - mean_absolute_error: 0.1896 - val_loss: 0.1147 - val_mean_absolute_error: 0.2064\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0879 - mean_absolute_error: 0.1894 - val_loss: 0.1155 - val_mean_absolute_error: 0.2071\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0881 - mean_absolute_error: 0.1888 - val_loss: 0.1153 - val_mean_absolute_error: 0.2050\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0870 - mean_absolute_error: 0.1889 - val_loss: 0.1166 - val_mean_absolute_error: 0.2042\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 778us/step - loss: 0.0872 - mean_absolute_error: 0.1877 - val_loss: 0.1169 - val_mean_absolute_error: 0.2055\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0886 - mean_absolute_error: 0.1888 - val_loss: 0.1134 - val_mean_absolute_error: 0.2054\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 709us/step - loss: 0.0862 - mean_absolute_error: 0.1884 - val_loss: 0.1203 - val_mean_absolute_error: 0.2110\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0863 - mean_absolute_error: 0.1877 - val_loss: 0.1179 - val_mean_absolute_error: 0.2067\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0863 - mean_absolute_error: 0.1874 - val_loss: 0.1140 - val_mean_absolute_error: 0.2032\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 785us/step - loss: 0.0862 - mean_absolute_error: 0.1870 - val_loss: 0.1157 - val_mean_absolute_error: 0.2058\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 858us/step - loss: 0.0859 - mean_absolute_error: 0.1873 - val_loss: 0.1191 - val_mean_absolute_error: 0.2054\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 700us/step - loss: 0.0864 - mean_absolute_error: 0.1877 - val_loss: 0.1158 - val_mean_absolute_error: 0.2059\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 687us/step - loss: 0.0853 - mean_absolute_error: 0.1871 - val_loss: 0.1150 - val_mean_absolute_error: 0.2037\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.0863 - mean_absolute_error: 0.1867 - val_loss: 0.1159 - val_mean_absolute_error: 0.2086\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 903us/step - loss: 0.0852 - mean_absolute_error: 0.1860 - val_loss: 0.1133 - val_mean_absolute_error: 0.2019\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 907us/step - loss: 0.0857 - mean_absolute_error: 0.1868 - val_loss: 0.1152 - val_mean_absolute_error: 0.2061\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0852 - mean_absolute_error: 0.1874 - val_loss: 0.1138 - val_mean_absolute_error: 0.2022\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0839 - mean_absolute_error: 0.1855 - val_loss: 0.1179 - val_mean_absolute_error: 0.2056\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0841 - mean_absolute_error: 0.1863 - val_loss: 0.1160 - val_mean_absolute_error: 0.2050\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 867us/step - loss: 0.0863 - mean_absolute_error: 0.1876 - val_loss: 0.1214 - val_mean_absolute_error: 0.2091\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.0858 - mean_absolute_error: 0.1870 - val_loss: 0.1163 - val_mean_absolute_error: 0.2060\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0835 - mean_absolute_error: 0.1858 - val_loss: 0.1151 - val_mean_absolute_error: 0.2036\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0833 - mean_absolute_error: 0.1851 - val_loss: 0.1221 - val_mean_absolute_error: 0.2108\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0834 - mean_absolute_error: 0.1855 - val_loss: 0.1195 - val_mean_absolute_error: 0.2076\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0831 - mean_absolute_error: 0.1849 - val_loss: 0.1140 - val_mean_absolute_error: 0.2035\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0825 - mean_absolute_error: 0.1845 - val_loss: 0.1144 - val_mean_absolute_error: 0.2031\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0834 - mean_absolute_error: 0.1855 - val_loss: 0.1159 - val_mean_absolute_error: 0.2046\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0835 - mean_absolute_error: 0.1857 - val_loss: 0.1167 - val_mean_absolute_error: 0.2045\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.0832 - mean_absolute_error: 0.1849 - val_loss: 0.1124 - val_mean_absolute_error: 0.2032\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.0818 - mean_absolute_error: 0.1836 - val_loss: 0.1119 - val_mean_absolute_error: 0.2040\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0815 - mean_absolute_error: 0.1836 - val_loss: 0.1180 - val_mean_absolute_error: 0.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 694us/step - loss: 0.0818 - mean_absolute_error: 0.1844 - val_loss: 0.1163 - val_mean_absolute_error: 0.2032\n",
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0817 - mean_absolute_error: 0.1830 - val_loss: 0.1133 - val_mean_absolute_error: 0.2023\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.0818 - mean_absolute_error: 0.1846 - val_loss: 0.1179 - val_mean_absolute_error: 0.2055\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0815 - mean_absolute_error: 0.1844 - val_loss: 0.1143 - val_mean_absolute_error: 0.2040\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0808 - mean_absolute_error: 0.1824 - val_loss: 0.1163 - val_mean_absolute_error: 0.2038\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0809 - mean_absolute_error: 0.1831 - val_loss: 0.1178 - val_mean_absolute_error: 0.2032\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0808 - mean_absolute_error: 0.1831 - val_loss: 0.1154 - val_mean_absolute_error: 0.2064\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0815 - mean_absolute_error: 0.1839 - val_loss: 0.1115 - val_mean_absolute_error: 0.2038\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0808 - mean_absolute_error: 0.1836 - val_loss: 0.1133 - val_mean_absolute_error: 0.2012\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0817 - mean_absolute_error: 0.1837 - val_loss: 0.1138 - val_mean_absolute_error: 0.2033\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0811 - mean_absolute_error: 0.1832 - val_loss: 0.1155 - val_mean_absolute_error: 0.2069\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0807 - mean_absolute_error: 0.1837 - val_loss: 0.1127 - val_mean_absolute_error: 0.2009\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0792 - mean_absolute_error: 0.1823 - val_loss: 0.1134 - val_mean_absolute_error: 0.2017\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0806 - mean_absolute_error: 0.1840 - val_loss: 0.1131 - val_mean_absolute_error: 0.2020\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0798 - mean_absolute_error: 0.1823 - val_loss: 0.1131 - val_mean_absolute_error: 0.2039\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 768us/step - loss: 0.0801 - mean_absolute_error: 0.1831 - val_loss: 0.1164 - val_mean_absolute_error: 0.2067\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0784 - mean_absolute_error: 0.1816 - val_loss: 0.1139 - val_mean_absolute_error: 0.2015\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0804 - mean_absolute_error: 0.1832 - val_loss: 0.1152 - val_mean_absolute_error: 0.2072\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0785 - mean_absolute_error: 0.1816 - val_loss: 0.1135 - val_mean_absolute_error: 0.2022\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0794 - mean_absolute_error: 0.1834 - val_loss: 0.1129 - val_mean_absolute_error: 0.2023\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0788 - mean_absolute_error: 0.1827 - val_loss: 0.1112 - val_mean_absolute_error: 0.2060\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0789 - mean_absolute_error: 0.1819 - val_loss: 0.1129 - val_mean_absolute_error: 0.2019\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 699us/step - loss: 0.0793 - mean_absolute_error: 0.1822 - val_loss: 0.1118 - val_mean_absolute_error: 0.2011\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0783 - mean_absolute_error: 0.1814 - val_loss: 0.1113 - val_mean_absolute_error: 0.1999\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0783 - mean_absolute_error: 0.1814 - val_loss: 0.1135 - val_mean_absolute_error: 0.2013\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0784 - mean_absolute_error: 0.1821 - val_loss: 0.1107 - val_mean_absolute_error: 0.1994\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0795 - mean_absolute_error: 0.1826 - val_loss: 0.1136 - val_mean_absolute_error: 0.2011\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0783 - mean_absolute_error: 0.1818 - val_loss: 0.1158 - val_mean_absolute_error: 0.2064\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 778us/step - loss: 0.0792 - mean_absolute_error: 0.1836 - val_loss: 0.1130 - val_mean_absolute_error: 0.1998\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 714us/step - loss: 0.0781 - mean_absolute_error: 0.1812 - val_loss: 0.1110 - val_mean_absolute_error: 0.1995\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0773 - mean_absolute_error: 0.1810 - val_loss: 0.1114 - val_mean_absolute_error: 0.2005\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0779 - mean_absolute_error: 0.1815 - val_loss: 0.1120 - val_mean_absolute_error: 0.1993\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0776 - mean_absolute_error: 0.1819 - val_loss: 0.1157 - val_mean_absolute_error: 0.2026\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0776 - mean_absolute_error: 0.1812 - val_loss: 0.1160 - val_mean_absolute_error: 0.2038\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 688us/step - loss: 0.0780 - mean_absolute_error: 0.1822 - val_loss: 0.1116 - val_mean_absolute_error: 0.1999\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.0777 - mean_absolute_error: 0.1818 - val_loss: 0.1169 - val_mean_absolute_error: 0.2040\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 826us/step - loss: 0.0774 - mean_absolute_error: 0.1808 - val_loss: 0.1108 - val_mean_absolute_error: 0.1997\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0774 - mean_absolute_error: 0.1814 - val_loss: 0.1119 - val_mean_absolute_error: 0.2040\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 875us/step - loss: 0.0772 - mean_absolute_error: 0.1800 - val_loss: 0.1159 - val_mean_absolute_error: 0.2027\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 893us/step - loss: 0.0764 - mean_absolute_error: 0.1800 - val_loss: 0.1135 - val_mean_absolute_error: 0.2007\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0769 - mean_absolute_error: 0.1802 - val_loss: 0.1126 - val_mean_absolute_error: 0.2011\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.0773 - mean_absolute_error: 0.1801 - val_loss: 0.1118 - val_mean_absolute_error: 0.2001\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0775 - mean_absolute_error: 0.1819 - val_loss: 0.1137 - val_mean_absolute_error: 0.2016\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 843us/step - loss: 0.0777 - mean_absolute_error: 0.1814 - val_loss: 0.1138 - val_mean_absolute_error: 0.2030\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 773us/step - loss: 0.0764 - mean_absolute_error: 0.1807 - val_loss: 0.1141 - val_mean_absolute_error: 0.2009\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 768us/step - loss: 0.0783 - mean_absolute_error: 0.1816 - val_loss: 0.1125 - val_mean_absolute_error: 0.2025\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0766 - mean_absolute_error: 0.1801 - val_loss: 0.1135 - val_mean_absolute_error: 0.2019\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0762 - mean_absolute_error: 0.1803 - val_loss: 0.1135 - val_mean_absolute_error: 0.2019\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0761 - mean_absolute_error: 0.1796 - val_loss: 0.1131 - val_mean_absolute_error: 0.1996\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.0766 - mean_absolute_error: 0.1802 - val_loss: 0.1157 - val_mean_absolute_error: 0.2004\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0767 - mean_absolute_error: 0.1811 - val_loss: 0.1145 - val_mean_absolute_error: 0.2003\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 848us/step - loss: 0.0770 - mean_absolute_error: 0.1801 - val_loss: 0.1132 - val_mean_absolute_error: 0.2040\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0765 - mean_absolute_error: 0.1807 - val_loss: 0.1174 - val_mean_absolute_error: 0.2060\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.0771 - mean_absolute_error: 0.1803 - val_loss: 0.1123 - val_mean_absolute_error: 0.2014\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0770 - mean_absolute_error: 0.1800 - val_loss: 0.1121 - val_mean_absolute_error: 0.2000\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 694us/step - loss: 0.0756 - mean_absolute_error: 0.1791 - val_loss: 0.1164 - val_mean_absolute_error: 0.2050\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 684us/step - loss: 0.0760 - mean_absolute_error: 0.1797 - val_loss: 0.1139 - val_mean_absolute_error: 0.2004\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0765 - mean_absolute_error: 0.1805 - val_loss: 0.1181 - val_mean_absolute_error: 0.2119\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0759 - mean_absolute_error: 0.1793 - val_loss: 0.1129 - val_mean_absolute_error: 0.2009\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 714us/step - loss: 0.0754 - mean_absolute_error: 0.1798 - val_loss: 0.1152 - val_mean_absolute_error: 0.2034\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0762 - mean_absolute_error: 0.1794 - val_loss: 0.1112 - val_mean_absolute_error: 0.2001\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0755 - mean_absolute_error: 0.1783 - val_loss: 0.1143 - val_mean_absolute_error: 0.2054\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 764us/step - loss: 0.0761 - mean_absolute_error: 0.1801 - val_loss: 0.1136 - val_mean_absolute_error: 0.2008\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 836us/step - loss: 0.0752 - mean_absolute_error: 0.1789 - val_loss: 0.1179 - val_mean_absolute_error: 0.2046\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 791us/step - loss: 0.0755 - mean_absolute_error: 0.1786 - val_loss: 0.1139 - val_mean_absolute_error: 0.2008\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0755 - mean_absolute_error: 0.1795 - val_loss: 0.1135 - val_mean_absolute_error: 0.2020\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0764 - mean_absolute_error: 0.1800 - val_loss: 0.1166 - val_mean_absolute_error: 0.2024\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0756 - mean_absolute_error: 0.1792 - val_loss: 0.1169 - val_mean_absolute_error: 0.2027\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 709us/step - loss: 0.0756 - mean_absolute_error: 0.1795 - val_loss: 0.1161 - val_mean_absolute_error: 0.2020\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0757 - mean_absolute_error: 0.1793 - val_loss: 0.1147 - val_mean_absolute_error: 0.2021\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0758 - mean_absolute_error: 0.1796 - val_loss: 0.1136 - val_mean_absolute_error: 0.2010\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 691us/step - loss: 0.0745 - mean_absolute_error: 0.1786 - val_loss: 0.1143 - val_mean_absolute_error: 0.2012\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 843us/step - loss: 0.0749 - mean_absolute_error: 0.1787 - val_loss: 0.1158 - val_mean_absolute_error: 0.2004\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0744 - mean_absolute_error: 0.1783 - val_loss: 0.1112 - val_mean_absolute_error: 0.2014\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 711us/step - loss: 0.0752 - mean_absolute_error: 0.1795 - val_loss: 0.1111 - val_mean_absolute_error: 0.2014\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 914us/step - loss: 0.0751 - mean_absolute_error: 0.1795 - val_loss: 0.1129 - val_mean_absolute_error: 0.2046\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0741 - mean_absolute_error: 0.1775 - val_loss: 0.1132 - val_mean_absolute_error: 0.2000\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.0766 - mean_absolute_error: 0.1809 - val_loss: 0.1134 - val_mean_absolute_error: 0.1999\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0740 - mean_absolute_error: 0.1780 - val_loss: 0.1142 - val_mean_absolute_error: 0.2029\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0746 - mean_absolute_error: 0.1785 - val_loss: 0.1122 - val_mean_absolute_error: 0.1987\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.0741 - mean_absolute_error: 0.1782 - val_loss: 0.1145 - val_mean_absolute_error: 0.2037\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0753 - mean_absolute_error: 0.1798 - val_loss: 0.1132 - val_mean_absolute_error: 0.2008\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0743 - mean_absolute_error: 0.1778 - val_loss: 0.1132 - val_mean_absolute_error: 0.2009\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0752 - mean_absolute_error: 0.1798 - val_loss: 0.1143 - val_mean_absolute_error: 0.2011\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 699us/step - loss: 0.0739 - mean_absolute_error: 0.1772 - val_loss: 0.1113 - val_mean_absolute_error: 0.2001\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0745 - mean_absolute_error: 0.1788 - val_loss: 0.1128 - val_mean_absolute_error: 0.2001\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0733 - mean_absolute_error: 0.1774 - val_loss: 0.1119 - val_mean_absolute_error: 0.1993\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0737 - mean_absolute_error: 0.1780 - val_loss: 0.1131 - val_mean_absolute_error: 0.2035\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0738 - mean_absolute_error: 0.1779 - val_loss: 0.1114 - val_mean_absolute_error: 0.1992\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0740 - mean_absolute_error: 0.1785 - val_loss: 0.1108 - val_mean_absolute_error: 0.1990\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0729 - mean_absolute_error: 0.1773 - val_loss: 0.1120 - val_mean_absolute_error: 0.1998\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0737 - mean_absolute_error: 0.1775 - val_loss: 0.1112 - val_mean_absolute_error: 0.1984\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0742 - mean_absolute_error: 0.1791 - val_loss: 0.1146 - val_mean_absolute_error: 0.2000\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0736 - mean_absolute_error: 0.1777 - val_loss: 0.1194 - val_mean_absolute_error: 0.2004\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0734 - mean_absolute_error: 0.1778 - val_loss: 0.1122 - val_mean_absolute_error: 0.2017\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 764us/step - loss: 0.0730 - mean_absolute_error: 0.1781 - val_loss: 0.1154 - val_mean_absolute_error: 0.2001\n",
      "Epoch 192/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 714us/step - loss: 0.0732 - mean_absolute_error: 0.1775 - val_loss: 0.1175 - val_mean_absolute_error: 0.2044\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0729 - mean_absolute_error: 0.1769 - val_loss: 0.1128 - val_mean_absolute_error: 0.2066\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0734 - mean_absolute_error: 0.1773 - val_loss: 0.1159 - val_mean_absolute_error: 0.2018\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0742 - mean_absolute_error: 0.1791 - val_loss: 0.1129 - val_mean_absolute_error: 0.1990\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0725 - mean_absolute_error: 0.1763 - val_loss: 0.1150 - val_mean_absolute_error: 0.1995\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0736 - mean_absolute_error: 0.1780 - val_loss: 0.1188 - val_mean_absolute_error: 0.2024\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0729 - mean_absolute_error: 0.1776 - val_loss: 0.1206 - val_mean_absolute_error: 0.2040\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0738 - mean_absolute_error: 0.1778 - val_loss: 0.1173 - val_mean_absolute_error: 0.2015\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0736 - mean_absolute_error: 0.1779 - val_loss: 0.1144 - val_mean_absolute_error: 0.1999\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0724 - mean_absolute_error: 0.1771 - val_loss: 0.1123 - val_mean_absolute_error: 0.2016\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0721 - mean_absolute_error: 0.1769 - val_loss: 0.1224 - val_mean_absolute_error: 0.2038\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0736 - mean_absolute_error: 0.1785 - val_loss: 0.1141 - val_mean_absolute_error: 0.2002\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0729 - mean_absolute_error: 0.1785 - val_loss: 0.1172 - val_mean_absolute_error: 0.2006\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0731 - mean_absolute_error: 0.1774 - val_loss: 0.1120 - val_mean_absolute_error: 0.1985\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0728 - mean_absolute_error: 0.1769 - val_loss: 0.1127 - val_mean_absolute_error: 0.1974\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0728 - mean_absolute_error: 0.1771 - val_loss: 0.1118 - val_mean_absolute_error: 0.2000\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0731 - mean_absolute_error: 0.1780 - val_loss: 0.1174 - val_mean_absolute_error: 0.2020\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0723 - mean_absolute_error: 0.1767 - val_loss: 0.1127 - val_mean_absolute_error: 0.1985\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 739us/step - loss: 0.0726 - mean_absolute_error: 0.1768 - val_loss: 0.1106 - val_mean_absolute_error: 0.1975\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0726 - mean_absolute_error: 0.1773 - val_loss: 0.1117 - val_mean_absolute_error: 0.1979\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 778us/step - loss: 0.0728 - mean_absolute_error: 0.1771 - val_loss: 0.1156 - val_mean_absolute_error: 0.2051\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0731 - mean_absolute_error: 0.1787 - val_loss: 0.1115 - val_mean_absolute_error: 0.1987\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0724 - mean_absolute_error: 0.1765 - val_loss: 0.1156 - val_mean_absolute_error: 0.2001\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0727 - mean_absolute_error: 0.1765 - val_loss: 0.1112 - val_mean_absolute_error: 0.1985\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0720 - mean_absolute_error: 0.1767 - val_loss: 0.1111 - val_mean_absolute_error: 0.2012\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0721 - mean_absolute_error: 0.1764 - val_loss: 0.1139 - val_mean_absolute_error: 0.1986\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0726 - mean_absolute_error: 0.1772 - val_loss: 0.1118 - val_mean_absolute_error: 0.1986\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0717 - mean_absolute_error: 0.1757 - val_loss: 0.1133 - val_mean_absolute_error: 0.1985\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0713 - mean_absolute_error: 0.1766 - val_loss: 0.1142 - val_mean_absolute_error: 0.2047\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0726 - mean_absolute_error: 0.1771 - val_loss: 0.1177 - val_mean_absolute_error: 0.2034\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 790us/step - loss: 0.0717 - mean_absolute_error: 0.1766 - val_loss: 0.1159 - val_mean_absolute_error: 0.1996\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0713 - mean_absolute_error: 0.1757 - val_loss: 0.1226 - val_mean_absolute_error: 0.2046\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0725 - mean_absolute_error: 0.1778 - val_loss: 0.1153 - val_mean_absolute_error: 0.1997\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 800us/step - loss: 0.0725 - mean_absolute_error: 0.1765 - val_loss: 0.1183 - val_mean_absolute_error: 0.2011\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 904us/step - loss: 0.0720 - mean_absolute_error: 0.1767 - val_loss: 0.1157 - val_mean_absolute_error: 0.2002\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0726 - mean_absolute_error: 0.1770 - val_loss: 0.1162 - val_mean_absolute_error: 0.1997\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0736 - mean_absolute_error: 0.1772 - val_loss: 0.1175 - val_mean_absolute_error: 0.1989\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0719 - mean_absolute_error: 0.1773 - val_loss: 0.1185 - val_mean_absolute_error: 0.2074\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0712 - mean_absolute_error: 0.1754 - val_loss: 0.1143 - val_mean_absolute_error: 0.2006\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0712 - mean_absolute_error: 0.1763 - val_loss: 0.1156 - val_mean_absolute_error: 0.2004\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 781us/step - loss: 0.0713 - mean_absolute_error: 0.1767 - val_loss: 0.1151 - val_mean_absolute_error: 0.1990\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 889us/step - loss: 0.0722 - mean_absolute_error: 0.1777 - val_loss: 0.1136 - val_mean_absolute_error: 0.1975\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 775us/step - loss: 0.0709 - mean_absolute_error: 0.1751 - val_loss: 0.1145 - val_mean_absolute_error: 0.1994\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 887us/step - loss: 0.0728 - mean_absolute_error: 0.1769 - val_loss: 0.1145 - val_mean_absolute_error: 0.1982\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 878us/step - loss: 0.0707 - mean_absolute_error: 0.1750 - val_loss: 0.1116 - val_mean_absolute_error: 0.1974\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 849us/step - loss: 0.0718 - mean_absolute_error: 0.1769 - val_loss: 0.1165 - val_mean_absolute_error: 0.2011\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0708 - mean_absolute_error: 0.1757 - val_loss: 0.1187 - val_mean_absolute_error: 0.2013\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0715 - mean_absolute_error: 0.1754 - val_loss: 0.1145 - val_mean_absolute_error: 0.1997\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0710 - mean_absolute_error: 0.1759 - val_loss: 0.1147 - val_mean_absolute_error: 0.2001\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 0s 699us/step - loss: 0.0706 - mean_absolute_error: 0.1754 - val_loss: 0.1139 - val_mean_absolute_error: 0.1996\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0721 - mean_absolute_error: 0.1759 - val_loss: 0.1169 - val_mean_absolute_error: 0.2100\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0711 - mean_absolute_error: 0.1766 - val_loss: 0.1152 - val_mean_absolute_error: 0.1988\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0713 - mean_absolute_error: 0.1762 - val_loss: 0.1167 - val_mean_absolute_error: 0.2025\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0725 - mean_absolute_error: 0.1768 - val_loss: 0.1160 - val_mean_absolute_error: 0.2019\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0705 - mean_absolute_error: 0.1751 - val_loss: 0.1188 - val_mean_absolute_error: 0.2020\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0709 - mean_absolute_error: 0.1753 - val_loss: 0.1128 - val_mean_absolute_error: 0.1994\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0707 - mean_absolute_error: 0.1758 - val_loss: 0.1120 - val_mean_absolute_error: 0.1980\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0715 - mean_absolute_error: 0.1757 - val_loss: 0.1178 - val_mean_absolute_error: 0.2013\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0714 - mean_absolute_error: 0.1755 - val_loss: 0.1100 - val_mean_absolute_error: 0.1972\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0711 - mean_absolute_error: 0.1760 - val_loss: 0.1152 - val_mean_absolute_error: 0.1990\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0710 - mean_absolute_error: 0.1752 - val_loss: 0.1200 - val_mean_absolute_error: 0.2036\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0717 - mean_absolute_error: 0.1767 - val_loss: 0.1165 - val_mean_absolute_error: 0.2016\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0721 - mean_absolute_error: 0.1765 - val_loss: 0.1141 - val_mean_absolute_error: 0.1993\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0717 - mean_absolute_error: 0.1770 - val_loss: 0.1152 - val_mean_absolute_error: 0.1991\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0706 - mean_absolute_error: 0.1755 - val_loss: 0.1155 - val_mean_absolute_error: 0.1982\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0714 - mean_absolute_error: 0.1757 - val_loss: 0.1165 - val_mean_absolute_error: 0.1996\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0707 - mean_absolute_error: 0.1754 - val_loss: 0.1139 - val_mean_absolute_error: 0.1976\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0706 - mean_absolute_error: 0.1746 - val_loss: 0.1174 - val_mean_absolute_error: 0.1995\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0706 - mean_absolute_error: 0.1759 - val_loss: 0.1156 - val_mean_absolute_error: 0.1981\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0711 - mean_absolute_error: 0.1756 - val_loss: 0.1149 - val_mean_absolute_error: 0.1982\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0712 - mean_absolute_error: 0.1758 - val_loss: 0.1159 - val_mean_absolute_error: 0.1992\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0713 - mean_absolute_error: 0.1753 - val_loss: 0.1175 - val_mean_absolute_error: 0.1994\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0701 - mean_absolute_error: 0.1744 - val_loss: 0.1142 - val_mean_absolute_error: 0.1974\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0703 - mean_absolute_error: 0.1748 - val_loss: 0.1157 - val_mean_absolute_error: 0.1985\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0703 - mean_absolute_error: 0.1752 - val_loss: 0.1153 - val_mean_absolute_error: 0.1988\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0716 - mean_absolute_error: 0.1754 - val_loss: 0.1166 - val_mean_absolute_error: 0.2011\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0707 - mean_absolute_error: 0.1756 - val_loss: 0.1142 - val_mean_absolute_error: 0.1988\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.0703 - mean_absolute_error: 0.1754 - val_loss: 0.1147 - val_mean_absolute_error: 0.2009\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0711 - mean_absolute_error: 0.1757 - val_loss: 0.1163 - val_mean_absolute_error: 0.1991\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 709us/step - loss: 0.0706 - mean_absolute_error: 0.1749 - val_loss: 0.1142 - val_mean_absolute_error: 0.1989\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0708 - mean_absolute_error: 0.1752 - val_loss: 0.1189 - val_mean_absolute_error: 0.2000\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0703 - mean_absolute_error: 0.1755 - val_loss: 0.1127 - val_mean_absolute_error: 0.1974\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0691 - mean_absolute_error: 0.1740 - val_loss: 0.1161 - val_mean_absolute_error: 0.2016\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0708 - mean_absolute_error: 0.1757 - val_loss: 0.1190 - val_mean_absolute_error: 0.2024\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0705 - mean_absolute_error: 0.1759 - val_loss: 0.1131 - val_mean_absolute_error: 0.1992\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.0701 - mean_absolute_error: 0.1752 - val_loss: 0.1149 - val_mean_absolute_error: 0.1982\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 777us/step - loss: 0.0706 - mean_absolute_error: 0.1751 - val_loss: 0.1138 - val_mean_absolute_error: 0.2017\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 853us/step - loss: 0.0709 - mean_absolute_error: 0.1753 - val_loss: 0.1158 - val_mean_absolute_error: 0.2007\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0702 - mean_absolute_error: 0.1755 - val_loss: 0.1173 - val_mean_absolute_error: 0.1993\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0697 - mean_absolute_error: 0.1747 - val_loss: 0.1196 - val_mean_absolute_error: 0.2002\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0705 - mean_absolute_error: 0.1755 - val_loss: 0.1168 - val_mean_absolute_error: 0.2004\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0701 - mean_absolute_error: 0.1754 - val_loss: 0.1150 - val_mean_absolute_error: 0.2031\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0701 - mean_absolute_error: 0.1753 - val_loss: 0.1192 - val_mean_absolute_error: 0.2021\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0708 - mean_absolute_error: 0.1753 - val_loss: 0.1144 - val_mean_absolute_error: 0.1989\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 854us/step - loss: 0.0704 - mean_absolute_error: 0.1741 - val_loss: 0.1252 - val_mean_absolute_error: 0.2065\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0709 - mean_absolute_error: 0.1764 - val_loss: 0.1132 - val_mean_absolute_error: 0.1988\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 791us/step - loss: 0.0695 - mean_absolute_error: 0.1745 - val_loss: 0.1162 - val_mean_absolute_error: 0.1980\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0705 - mean_absolute_error: 0.1748 - val_loss: 0.1167 - val_mean_absolute_error: 0.2044\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 883us/step - loss: 0.0695 - mean_absolute_error: 0.1749 - val_loss: 0.1132 - val_mean_absolute_error: 0.1983\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 855us/step - loss: 0.0699 - mean_absolute_error: 0.1743 - val_loss: 0.1160 - val_mean_absolute_error: 0.1982\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0707 - mean_absolute_error: 0.1764 - val_loss: 0.1182 - val_mean_absolute_error: 0.2026\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0706 - mean_absolute_error: 0.1743 - val_loss: 0.1188 - val_mean_absolute_error: 0.2005\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0709 - mean_absolute_error: 0.1757 - val_loss: 0.1135 - val_mean_absolute_error: 0.1984\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0691 - mean_absolute_error: 0.1740 - val_loss: 0.1135 - val_mean_absolute_error: 0.2009\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0704 - mean_absolute_error: 0.1743 - val_loss: 0.1118 - val_mean_absolute_error: 0.1979\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0702 - mean_absolute_error: 0.1754 - val_loss: 0.1129 - val_mean_absolute_error: 0.1972\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0693 - mean_absolute_error: 0.1739 - val_loss: 0.1228 - val_mean_absolute_error: 0.2008\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0723 - mean_absolute_error: 0.1763 - val_loss: 0.1153 - val_mean_absolute_error: 0.1998\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0700 - mean_absolute_error: 0.1741 - val_loss: 0.1235 - val_mean_absolute_error: 0.2029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2330db46910>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create model-2\n",
    "model_2 = keras.Sequential(name='model-2')\n",
    "model_2.add(layers.Dense(16, activation='relu', input_shape=(21,)))\n",
    "model_2.add(layers.Dense(16, activation='relu'))\n",
    "model_2.add(layers.Dense(1))\n",
    "\n",
    "# Set the optimizer, loss function and metrics function for training\n",
    "model_2.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Set callback function\n",
    "log_dir = os.path.join('lab2-logs', 'model-2')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-2.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "# Train model-2\n",
    "model_2.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model-3: model of adding weights regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 46s - loss: 1.1649 - mean_absolute_error: 0.6518WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0120s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.4447s). Check your callbacks.\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.4417 - mean_absolute_error: 0.3468 - val_loss: 0.3137 - val_mean_absolute_error: 0.3050\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 994us/step - loss: 0.2976 - mean_absolute_error: 0.2873 - val_loss: 0.2670 - val_mean_absolute_error: 0.2674\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.2605 - mean_absolute_error: 0.2647 - val_loss: 0.2477 - val_mean_absolute_error: 0.2580\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.2395 - mean_absolute_error: 0.2523 - val_loss: 0.2354 - val_mean_absolute_error: 0.2457\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.2284 - mean_absolute_error: 0.2436 - val_loss: 0.2191 - val_mean_absolute_error: 0.2420\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 975us/step - loss: 0.2109 - mean_absolute_error: 0.2328 - val_loss: 0.2045 - val_mean_absolute_error: 0.2247\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.1952 - mean_absolute_error: 0.2204 - val_loss: 0.2159 - val_mean_absolute_error: 0.2368\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.1859 - mean_absolute_error: 0.2148 - val_loss: 0.1887 - val_mean_absolute_error: 0.2182\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1781 - mean_absolute_error: 0.2112 - val_loss: 0.1840 - val_mean_absolute_error: 0.2158\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1727 - mean_absolute_error: 0.2077 - val_loss: 0.1841 - val_mean_absolute_error: 0.2174\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.1676 - mean_absolute_error: 0.2057 - val_loss: 0.1866 - val_mean_absolute_error: 0.2330\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1644 - mean_absolute_error: 0.2071 - val_loss: 0.1727 - val_mean_absolute_error: 0.2145\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1583 - mean_absolute_error: 0.2002 - val_loss: 0.1717 - val_mean_absolute_error: 0.2102\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.1558 - mean_absolute_error: 0.1992 - val_loss: 0.1689 - val_mean_absolute_error: 0.2136\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.1535 - mean_absolute_error: 0.1993 - val_loss: 0.1641 - val_mean_absolute_error: 0.2055\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 970us/step - loss: 0.1508 - mean_absolute_error: 0.1972 - val_loss: 0.1642 - val_mean_absolute_error: 0.2023\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.1430 - mean_absolute_error: 0.1929 - val_loss: 0.1602 - val_mean_absolute_error: 0.2047\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.1417 - mean_absolute_error: 0.1945 - val_loss: 0.1588 - val_mean_absolute_error: 0.2024\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1381 - mean_absolute_error: 0.1894 - val_loss: 0.1570 - val_mean_absolute_error: 0.2002\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.1388 - mean_absolute_error: 0.1913 - val_loss: 0.1635 - val_mean_absolute_error: 0.2080\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 930us/step - loss: 0.1363 - mean_absolute_error: 0.1901 - val_loss: 0.1543 - val_mean_absolute_error: 0.1994\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.1353 - mean_absolute_error: 0.1889 - val_loss: 0.1638 - val_mean_absolute_error: 0.2170\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 930us/step - loss: 0.1310 - mean_absolute_error: 0.1874 - val_loss: 0.1566 - val_mean_absolute_error: 0.2041\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1304 - mean_absolute_error: 0.1895 - val_loss: 0.1520 - val_mean_absolute_error: 0.2086\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 866us/step - loss: 0.1294 - mean_absolute_error: 0.1884 - val_loss: 0.1581 - val_mean_absolute_error: 0.2046\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 867us/step - loss: 0.1272 - mean_absolute_error: 0.1853 - val_loss: 0.1530 - val_mean_absolute_error: 0.2000\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.1274 - mean_absolute_error: 0.1888 - val_loss: 0.1455 - val_mean_absolute_error: 0.2019\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 866us/step - loss: 0.1260 - mean_absolute_error: 0.1876 - val_loss: 0.1541 - val_mean_absolute_error: 0.2241\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.1247 - mean_absolute_error: 0.1866 - val_loss: 0.1491 - val_mean_absolute_error: 0.2060\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.1238 - mean_absolute_error: 0.1849 - val_loss: 0.1511 - val_mean_absolute_error: 0.2024\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1227 - mean_absolute_error: 0.1865 - val_loss: 0.1433 - val_mean_absolute_error: 0.1996\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.1206 - mean_absolute_error: 0.1829 - val_loss: 0.1486 - val_mean_absolute_error: 0.2037\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.1197 - mean_absolute_error: 0.1847 - val_loss: 0.1480 - val_mean_absolute_error: 0.1999\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.1207 - mean_absolute_error: 0.1867 - val_loss: 0.1401 - val_mean_absolute_error: 0.1989\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1184 - mean_absolute_error: 0.1839 - val_loss: 0.1452 - val_mean_absolute_error: 0.2006\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.1158 - mean_absolute_error: 0.1813 - val_loss: 0.1421 - val_mean_absolute_error: 0.1970\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.1151 - mean_absolute_error: 0.1814 - val_loss: 0.1424 - val_mean_absolute_error: 0.1993\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.1137 - mean_absolute_error: 0.1800 - val_loss: 0.1512 - val_mean_absolute_error: 0.2004\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.1132 - mean_absolute_error: 0.1804 - val_loss: 0.1444 - val_mean_absolute_error: 0.2009\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.1142 - mean_absolute_error: 0.1834 - val_loss: 0.1402 - val_mean_absolute_error: 0.1952\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.1131 - mean_absolute_error: 0.1809 - val_loss: 0.1439 - val_mean_absolute_error: 0.2091\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.1133 - mean_absolute_error: 0.1819 - val_loss: 0.1605 - val_mean_absolute_error: 0.2107\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1099 - mean_absolute_error: 0.1791 - val_loss: 0.1502 - val_mean_absolute_error: 0.2046\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.1131 - mean_absolute_error: 0.1804 - val_loss: 0.1395 - val_mean_absolute_error: 0.1995\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1170 - mean_absolute_error: 0.1851 - val_loss: 0.1414 - val_mean_absolute_error: 0.1975\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.1081 - mean_absolute_error: 0.1779 - val_loss: 0.1387 - val_mean_absolute_error: 0.1972\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.1109 - mean_absolute_error: 0.1811 - val_loss: 0.1412 - val_mean_absolute_error: 0.1996\n",
      "Epoch 48/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.1086 - mean_absolute_error: 0.1781 - val_loss: 0.1365 - val_mean_absolute_error: 0.1953\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 980us/step - loss: 0.1061 - mean_absolute_error: 0.1766 - val_loss: 0.1360 - val_mean_absolute_error: 0.1930\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1076 - mean_absolute_error: 0.1792 - val_loss: 0.1372 - val_mean_absolute_error: 0.1979\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.1088 - mean_absolute_error: 0.1796 - val_loss: 0.1436 - val_mean_absolute_error: 0.2009\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 970us/step - loss: 0.1064 - mean_absolute_error: 0.1771 - val_loss: 0.1360 - val_mean_absolute_error: 0.1960\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 955us/step - loss: 0.1059 - mean_absolute_error: 0.1774 - val_loss: 0.1317 - val_mean_absolute_error: 0.1911\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.1052 - mean_absolute_error: 0.1777 - val_loss: 0.1310 - val_mean_absolute_error: 0.1925\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.1055 - mean_absolute_error: 0.1773 - val_loss: 0.1548 - val_mean_absolute_error: 0.2041\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.1061 - mean_absolute_error: 0.1789 - val_loss: 0.1541 - val_mean_absolute_error: 0.2060\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.1062 - mean_absolute_error: 0.1793 - val_loss: 0.1436 - val_mean_absolute_error: 0.1989\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.1024 - mean_absolute_error: 0.1758 - val_loss: 0.1384 - val_mean_absolute_error: 0.1986\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 795us/step - loss: 0.1028 - mean_absolute_error: 0.1758 - val_loss: 0.1330 - val_mean_absolute_error: 0.1934\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.1019 - mean_absolute_error: 0.1768 - val_loss: 0.1332 - val_mean_absolute_error: 0.1937\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1007 - mean_absolute_error: 0.1731 - val_loss: 0.1326 - val_mean_absolute_error: 0.1930\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 834us/step - loss: 0.1013 - mean_absolute_error: 0.1747 - val_loss: 0.1366 - val_mean_absolute_error: 0.1966\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 898us/step - loss: 0.1006 - mean_absolute_error: 0.1752 - val_loss: 0.1324 - val_mean_absolute_error: 0.1928\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 909us/step - loss: 0.0997 - mean_absolute_error: 0.1748 - val_loss: 0.1448 - val_mean_absolute_error: 0.2064\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 866us/step - loss: 0.1034 - mean_absolute_error: 0.1768 - val_loss: 0.1413 - val_mean_absolute_error: 0.1953\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1039 - mean_absolute_error: 0.1759 - val_loss: 0.1317 - val_mean_absolute_error: 0.1946\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1049 - mean_absolute_error: 0.1774 - val_loss: 0.1362 - val_mean_absolute_error: 0.1963\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0966 - mean_absolute_error: 0.1711 - val_loss: 0.1417 - val_mean_absolute_error: 0.1984\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0973 - mean_absolute_error: 0.1729 - val_loss: 0.1354 - val_mean_absolute_error: 0.1935\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0992 - mean_absolute_error: 0.1742 - val_loss: 0.1396 - val_mean_absolute_error: 0.1968\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1023 - mean_absolute_error: 0.1771 - val_loss: 0.1521 - val_mean_absolute_error: 0.2059\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.1018 - mean_absolute_error: 0.1773 - val_loss: 0.1361 - val_mean_absolute_error: 0.2064\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0964 - mean_absolute_error: 0.1718 - val_loss: 0.1377 - val_mean_absolute_error: 0.1950\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.0972 - mean_absolute_error: 0.1729 - val_loss: 0.1266 - val_mean_absolute_error: 0.1911\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.1029 - mean_absolute_error: 0.1769 - val_loss: 0.1362 - val_mean_absolute_error: 0.2032\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0964 - mean_absolute_error: 0.1733 - val_loss: 0.1369 - val_mean_absolute_error: 0.1961\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0939 - mean_absolute_error: 0.1710 - val_loss: 0.1343 - val_mean_absolute_error: 0.2027\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0981 - mean_absolute_error: 0.1733 - val_loss: 0.1507 - val_mean_absolute_error: 0.2134\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 867us/step - loss: 0.0965 - mean_absolute_error: 0.1727 - val_loss: 0.1353 - val_mean_absolute_error: 0.2010\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0942 - mean_absolute_error: 0.1722 - val_loss: 0.1310 - val_mean_absolute_error: 0.1955\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0981 - mean_absolute_error: 0.1745 - val_loss: 0.1320 - val_mean_absolute_error: 0.1957\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0938 - mean_absolute_error: 0.1713 - val_loss: 0.1352 - val_mean_absolute_error: 0.1980\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0918 - mean_absolute_error: 0.1687 - val_loss: 0.1340 - val_mean_absolute_error: 0.1932\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0955 - mean_absolute_error: 0.1741 - val_loss: 0.1404 - val_mean_absolute_error: 0.2061\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0950 - mean_absolute_error: 0.1725 - val_loss: 0.1324 - val_mean_absolute_error: 0.1947\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0956 - mean_absolute_error: 0.1711 - val_loss: 0.1424 - val_mean_absolute_error: 0.1957\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0979 - mean_absolute_error: 0.1731 - val_loss: 0.1299 - val_mean_absolute_error: 0.1975\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0955 - mean_absolute_error: 0.1732 - val_loss: 0.1299 - val_mean_absolute_error: 0.1906\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0926 - mean_absolute_error: 0.1697 - val_loss: 0.1283 - val_mean_absolute_error: 0.1915\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0910 - mean_absolute_error: 0.1705 - val_loss: 0.1383 - val_mean_absolute_error: 0.1999\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0903 - mean_absolute_error: 0.1685 - val_loss: 0.1271 - val_mean_absolute_error: 0.1918\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0917 - mean_absolute_error: 0.1704 - val_loss: 0.1349 - val_mean_absolute_error: 0.1980\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0915 - mean_absolute_error: 0.1701 - val_loss: 0.1282 - val_mean_absolute_error: 0.1927\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0918 - mean_absolute_error: 0.1707 - val_loss: 0.1324 - val_mean_absolute_error: 0.1966\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 872us/step - loss: 0.0904 - mean_absolute_error: 0.1694 - val_loss: 0.1292 - val_mean_absolute_error: 0.1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0899 - mean_absolute_error: 0.1687 - val_loss: 0.1303 - val_mean_absolute_error: 0.1953\n",
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 936us/step - loss: 0.0898 - mean_absolute_error: 0.1686 - val_loss: 0.1305 - val_mean_absolute_error: 0.1956\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 935us/step - loss: 0.0924 - mean_absolute_error: 0.1722 - val_loss: 0.1361 - val_mean_absolute_error: 0.2010\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0910 - mean_absolute_error: 0.1690 - val_loss: 0.1366 - val_mean_absolute_error: 0.1992\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0940 - mean_absolute_error: 0.1715 - val_loss: 0.1316 - val_mean_absolute_error: 0.1987\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 990us/step - loss: 0.0886 - mean_absolute_error: 0.1675 - val_loss: 0.1287 - val_mean_absolute_error: 0.1905\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0885 - mean_absolute_error: 0.1676 - val_loss: 0.1283 - val_mean_absolute_error: 0.1955\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 936us/step - loss: 0.0903 - mean_absolute_error: 0.1691 - val_loss: 0.1274 - val_mean_absolute_error: 0.1906\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0954 - mean_absolute_error: 0.1738 - val_loss: 0.1288 - val_mean_absolute_error: 0.1973\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0887 - mean_absolute_error: 0.1694 - val_loss: 0.1272 - val_mean_absolute_error: 0.1932\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0886 - mean_absolute_error: 0.1685 - val_loss: 0.1374 - val_mean_absolute_error: 0.1956\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0908 - mean_absolute_error: 0.1705 - val_loss: 0.1292 - val_mean_absolute_error: 0.1934\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0901 - mean_absolute_error: 0.1681 - val_loss: 0.1338 - val_mean_absolute_error: 0.2023\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 867us/step - loss: 0.0959 - mean_absolute_error: 0.1734 - val_loss: 0.1835 - val_mean_absolute_error: 0.2329\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0902 - mean_absolute_error: 0.1699 - val_loss: 0.1270 - val_mean_absolute_error: 0.1900\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0848 - mean_absolute_error: 0.1657 - val_loss: 0.1342 - val_mean_absolute_error: 0.1954\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0870 - mean_absolute_error: 0.1670 - val_loss: 0.1291 - val_mean_absolute_error: 0.1915\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 882us/step - loss: 0.0890 - mean_absolute_error: 0.1690 - val_loss: 0.1319 - val_mean_absolute_error: 0.1979\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 866us/step - loss: 0.0895 - mean_absolute_error: 0.1685 - val_loss: 0.1407 - val_mean_absolute_error: 0.1960\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0886 - mean_absolute_error: 0.1679 - val_loss: 0.1303 - val_mean_absolute_error: 0.1963\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0871 - mean_absolute_error: 0.1678 - val_loss: 0.1340 - val_mean_absolute_error: 0.1960\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0910 - mean_absolute_error: 0.1706 - val_loss: 0.1326 - val_mean_absolute_error: 0.1942\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0868 - mean_absolute_error: 0.1674 - val_loss: 0.1334 - val_mean_absolute_error: 0.1947\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0863 - mean_absolute_error: 0.1665 - val_loss: 0.1440 - val_mean_absolute_error: 0.2032\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0883 - mean_absolute_error: 0.1692 - val_loss: 0.1376 - val_mean_absolute_error: 0.2123\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 995us/step - loss: 0.0889 - mean_absolute_error: 0.1697 - val_loss: 0.1263 - val_mean_absolute_error: 0.1892\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0841 - mean_absolute_error: 0.1646 - val_loss: 0.1322 - val_mean_absolute_error: 0.1961\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0913 - mean_absolute_error: 0.1698 - val_loss: 0.1363 - val_mean_absolute_error: 0.1976\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0856 - mean_absolute_error: 0.1669 - val_loss: 0.1302 - val_mean_absolute_error: 0.1914\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0858 - mean_absolute_error: 0.1675 - val_loss: 0.1340 - val_mean_absolute_error: 0.1979\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0847 - mean_absolute_error: 0.1653 - val_loss: 0.1269 - val_mean_absolute_error: 0.1940\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0856 - mean_absolute_error: 0.1675 - val_loss: 0.1279 - val_mean_absolute_error: 0.1909\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0843 - mean_absolute_error: 0.1653 - val_loss: 0.1384 - val_mean_absolute_error: 0.2025\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0992 - mean_absolute_error: 0.1751 - val_loss: 0.1324 - val_mean_absolute_error: 0.1978\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0890 - mean_absolute_error: 0.1694 - val_loss: 0.1310 - val_mean_absolute_error: 0.1937\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.0853 - mean_absolute_error: 0.1677 - val_loss: 0.1299 - val_mean_absolute_error: 0.1945\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0860 - mean_absolute_error: 0.1670 - val_loss: 0.1282 - val_mean_absolute_error: 0.1916\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0839 - mean_absolute_error: 0.1647 - val_loss: 0.1303 - val_mean_absolute_error: 0.1937\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0827 - mean_absolute_error: 0.1645 - val_loss: 0.1297 - val_mean_absolute_error: 0.1940\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.0852 - mean_absolute_error: 0.1677 - val_loss: 0.1281 - val_mean_absolute_error: 0.1917\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0833 - mean_absolute_error: 0.1644 - val_loss: 0.1298 - val_mean_absolute_error: 0.1956\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0817 - mean_absolute_error: 0.1636 - val_loss: 0.1316 - val_mean_absolute_error: 0.1926\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0973 - mean_absolute_error: 0.1750 - val_loss: 0.1279 - val_mean_absolute_error: 0.1927\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0851 - mean_absolute_error: 0.1653 - val_loss: 0.1372 - val_mean_absolute_error: 0.1992\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0854 - mean_absolute_error: 0.1671 - val_loss: 0.1272 - val_mean_absolute_error: 0.1904\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0854 - mean_absolute_error: 0.1670 - val_loss: 0.1314 - val_mean_absolute_error: 0.1983\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0834 - mean_absolute_error: 0.1647 - val_loss: 0.1339 - val_mean_absolute_error: 0.1994\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0841 - mean_absolute_error: 0.1666 - val_loss: 0.1390 - val_mean_absolute_error: 0.2003\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0830 - mean_absolute_error: 0.1646 - val_loss: 0.1367 - val_mean_absolute_error: 0.2005\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0845 - mean_absolute_error: 0.1671 - val_loss: 0.1334 - val_mean_absolute_error: 0.1951\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 0s 836us/step - loss: 0.0906 - mean_absolute_error: 0.1719 - val_loss: 0.1282 - val_mean_absolute_error: 0.1939\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 835us/step - loss: 0.0838 - mean_absolute_error: 0.1655 - val_loss: 0.1344 - val_mean_absolute_error: 0.1948\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0813 - mean_absolute_error: 0.1631 - val_loss: 0.1342 - val_mean_absolute_error: 0.1971\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0823 - mean_absolute_error: 0.1635 - val_loss: 0.1398 - val_mean_absolute_error: 0.2081\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0822 - mean_absolute_error: 0.1640 - val_loss: 0.1320 - val_mean_absolute_error: 0.1925\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0857 - mean_absolute_error: 0.1678 - val_loss: 0.1277 - val_mean_absolute_error: 0.1919\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0826 - mean_absolute_error: 0.1651 - val_loss: 0.1317 - val_mean_absolute_error: 0.1946\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0846 - mean_absolute_error: 0.1670 - val_loss: 0.1380 - val_mean_absolute_error: 0.1993\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0867 - mean_absolute_error: 0.1676 - val_loss: 0.1300 - val_mean_absolute_error: 0.1920\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0794 - mean_absolute_error: 0.1610 - val_loss: 0.1287 - val_mean_absolute_error: 0.1912\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0815 - mean_absolute_error: 0.1654 - val_loss: 0.1280 - val_mean_absolute_error: 0.1911\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0819 - mean_absolute_error: 0.1644 - val_loss: 0.1339 - val_mean_absolute_error: 0.1975\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0839 - mean_absolute_error: 0.1656 - val_loss: 0.1308 - val_mean_absolute_error: 0.1927\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0821 - mean_absolute_error: 0.1647 - val_loss: 0.1419 - val_mean_absolute_error: 0.2187\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0836 - mean_absolute_error: 0.1664 - val_loss: 0.1306 - val_mean_absolute_error: 0.1951\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0797 - mean_absolute_error: 0.1616 - val_loss: 0.1251 - val_mean_absolute_error: 0.1910\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0837 - mean_absolute_error: 0.1662 - val_loss: 0.1359 - val_mean_absolute_error: 0.1981\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0857 - mean_absolute_error: 0.1672 - val_loss: 0.1290 - val_mean_absolute_error: 0.1954\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0847 - mean_absolute_error: 0.1674 - val_loss: 0.1240 - val_mean_absolute_error: 0.1882\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0814 - mean_absolute_error: 0.1638 - val_loss: 0.1292 - val_mean_absolute_error: 0.1956\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0841 - mean_absolute_error: 0.1676 - val_loss: 0.1251 - val_mean_absolute_error: 0.2003\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 883us/step - loss: 0.0819 - mean_absolute_error: 0.1649 - val_loss: 0.1279 - val_mean_absolute_error: 0.1926\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 934us/step - loss: 0.0801 - mean_absolute_error: 0.1629 - val_loss: 0.1266 - val_mean_absolute_error: 0.1923\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 958us/step - loss: 0.0834 - mean_absolute_error: 0.1659 - val_loss: 0.1303 - val_mean_absolute_error: 0.1963\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0828 - mean_absolute_error: 0.1647 - val_loss: 0.1302 - val_mean_absolute_error: 0.1974\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0831 - mean_absolute_error: 0.1655 - val_loss: 0.1332 - val_mean_absolute_error: 0.1993\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0838 - mean_absolute_error: 0.1661 - val_loss: 0.1295 - val_mean_absolute_error: 0.1927\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0791 - mean_absolute_error: 0.1620 - val_loss: 0.1250 - val_mean_absolute_error: 0.1900\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0805 - mean_absolute_error: 0.1638 - val_loss: 0.1277 - val_mean_absolute_error: 0.1931\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 930us/step - loss: 0.0769 - mean_absolute_error: 0.1602 - val_loss: 0.1282 - val_mean_absolute_error: 0.1958\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0798 - mean_absolute_error: 0.1617 - val_loss: 0.1305 - val_mean_absolute_error: 0.1933\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0944 - mean_absolute_error: 0.1730 - val_loss: 0.1256 - val_mean_absolute_error: 0.1980\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0846 - mean_absolute_error: 0.1677 - val_loss: 0.1292 - val_mean_absolute_error: 0.1976\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0790 - mean_absolute_error: 0.1618 - val_loss: 0.1382 - val_mean_absolute_error: 0.1964\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0784 - mean_absolute_error: 0.1619 - val_loss: 0.1232 - val_mean_absolute_error: 0.1950\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0854 - mean_absolute_error: 0.1674 - val_loss: 0.1319 - val_mean_absolute_error: 0.1985\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0822 - mean_absolute_error: 0.1638 - val_loss: 0.1274 - val_mean_absolute_error: 0.1941\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0804 - mean_absolute_error: 0.1645 - val_loss: 0.1290 - val_mean_absolute_error: 0.1949\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0777 - mean_absolute_error: 0.1604 - val_loss: 0.1290 - val_mean_absolute_error: 0.1947\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0769 - mean_absolute_error: 0.1600 - val_loss: 0.1357 - val_mean_absolute_error: 0.1998\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 808us/step - loss: 0.0777 - mean_absolute_error: 0.1608 - val_loss: 0.1323 - val_mean_absolute_error: 0.1946\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0963 - mean_absolute_error: 0.1744 - val_loss: 0.1282 - val_mean_absolute_error: 0.1962\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0829 - mean_absolute_error: 0.1640 - val_loss: 0.1397 - val_mean_absolute_error: 0.2026\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0777 - mean_absolute_error: 0.1611 - val_loss: 0.1289 - val_mean_absolute_error: 0.1940\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0787 - mean_absolute_error: 0.1632 - val_loss: 0.1392 - val_mean_absolute_error: 0.1955\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0863 - mean_absolute_error: 0.1684 - val_loss: 0.1273 - val_mean_absolute_error: 0.1932\n",
      "Epoch 192/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 837us/step - loss: 0.0811 - mean_absolute_error: 0.1641 - val_loss: 0.1490 - val_mean_absolute_error: 0.2027\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0777 - mean_absolute_error: 0.1614 - val_loss: 0.1484 - val_mean_absolute_error: 0.2003\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0847 - mean_absolute_error: 0.1666 - val_loss: 0.1299 - val_mean_absolute_error: 0.1967\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0792 - mean_absolute_error: 0.1640 - val_loss: 0.1306 - val_mean_absolute_error: 0.1986\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0765 - mean_absolute_error: 0.1598 - val_loss: 0.1302 - val_mean_absolute_error: 0.1955\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0769 - mean_absolute_error: 0.1605 - val_loss: 0.1299 - val_mean_absolute_error: 0.1921\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 842us/step - loss: 0.0781 - mean_absolute_error: 0.1622 - val_loss: 0.1271 - val_mean_absolute_error: 0.1932\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0798 - mean_absolute_error: 0.1634 - val_loss: 0.1284 - val_mean_absolute_error: 0.1952\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0824 - mean_absolute_error: 0.1638 - val_loss: 0.1264 - val_mean_absolute_error: 0.1974\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0839 - mean_absolute_error: 0.1643 - val_loss: 0.1330 - val_mean_absolute_error: 0.1943\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0786 - mean_absolute_error: 0.1623 - val_loss: 0.1280 - val_mean_absolute_error: 0.1931\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0780 - mean_absolute_error: 0.1609 - val_loss: 0.1246 - val_mean_absolute_error: 0.1909\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0755 - mean_absolute_error: 0.1593 - val_loss: 0.1300 - val_mean_absolute_error: 0.1942\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0766 - mean_absolute_error: 0.1604 - val_loss: 0.1270 - val_mean_absolute_error: 0.1944\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0868 - mean_absolute_error: 0.1705 - val_loss: 0.1325 - val_mean_absolute_error: 0.1974\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0846 - mean_absolute_error: 0.1676 - val_loss: 0.1297 - val_mean_absolute_error: 0.1956\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0840 - mean_absolute_error: 0.1668 - val_loss: 0.1275 - val_mean_absolute_error: 0.1939\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0791 - mean_absolute_error: 0.1634 - val_loss: 0.1252 - val_mean_absolute_error: 0.1919\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0779 - mean_absolute_error: 0.1611 - val_loss: 0.1301 - val_mean_absolute_error: 0.1954\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0779 - mean_absolute_error: 0.1612 - val_loss: 0.1275 - val_mean_absolute_error: 0.1927\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0782 - mean_absolute_error: 0.1625 - val_loss: 0.1260 - val_mean_absolute_error: 0.1928\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0786 - mean_absolute_error: 0.1617 - val_loss: 0.1256 - val_mean_absolute_error: 0.1934\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0779 - mean_absolute_error: 0.1618 - val_loss: 0.1359 - val_mean_absolute_error: 0.2015\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0882 - mean_absolute_error: 0.1717 - val_loss: 0.1307 - val_mean_absolute_error: 0.2026\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0814 - mean_absolute_error: 0.1644 - val_loss: 0.1244 - val_mean_absolute_error: 0.1928\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0762 - mean_absolute_error: 0.1599 - val_loss: 0.1256 - val_mean_absolute_error: 0.1961\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 872us/step - loss: 0.0767 - mean_absolute_error: 0.1611 - val_loss: 0.1238 - val_mean_absolute_error: 0.1921\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0849 - mean_absolute_error: 0.1677 - val_loss: 0.1291 - val_mean_absolute_error: 0.1982\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0776 - mean_absolute_error: 0.1606 - val_loss: 0.1365 - val_mean_absolute_error: 0.2012\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0765 - mean_absolute_error: 0.1609 - val_loss: 0.1281 - val_mean_absolute_error: 0.1936\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0824 - mean_absolute_error: 0.1650 - val_loss: 0.1329 - val_mean_absolute_error: 0.1952\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0808 - mean_absolute_error: 0.1651 - val_loss: 0.1299 - val_mean_absolute_error: 0.1958\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0798 - mean_absolute_error: 0.1637 - val_loss: 0.1250 - val_mean_absolute_error: 0.1927\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 877us/step - loss: 0.0791 - mean_absolute_error: 0.1626 - val_loss: 0.1226 - val_mean_absolute_error: 0.1897\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0783 - mean_absolute_error: 0.1622 - val_loss: 0.1288 - val_mean_absolute_error: 0.1961\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0818 - mean_absolute_error: 0.1641 - val_loss: 0.1210 - val_mean_absolute_error: 0.1904\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.0783 - mean_absolute_error: 0.1627 - val_loss: 0.1292 - val_mean_absolute_error: 0.1936\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0783 - mean_absolute_error: 0.1622 - val_loss: 0.1314 - val_mean_absolute_error: 0.1960\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0782 - mean_absolute_error: 0.1612 - val_loss: 0.1264 - val_mean_absolute_error: 0.1956\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0780 - mean_absolute_error: 0.1618 - val_loss: 0.1345 - val_mean_absolute_error: 0.2098\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0765 - mean_absolute_error: 0.1605 - val_loss: 0.1267 - val_mean_absolute_error: 0.1940\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0823 - mean_absolute_error: 0.1644 - val_loss: 0.1290 - val_mean_absolute_error: 0.1926\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0796 - mean_absolute_error: 0.1634 - val_loss: 0.1260 - val_mean_absolute_error: 0.1919\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0790 - mean_absolute_error: 0.1621 - val_loss: 0.1385 - val_mean_absolute_error: 0.1987\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0781 - mean_absolute_error: 0.1618 - val_loss: 0.1278 - val_mean_absolute_error: 0.1942\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0746 - mean_absolute_error: 0.1589 - val_loss: 0.1295 - val_mean_absolute_error: 0.1931\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0785 - mean_absolute_error: 0.1631 - val_loss: 0.1266 - val_mean_absolute_error: 0.1910\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0774 - mean_absolute_error: 0.1605 - val_loss: 0.1265 - val_mean_absolute_error: 0.1936\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0833 - mean_absolute_error: 0.1667 - val_loss: 0.1306 - val_mean_absolute_error: 0.1944\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0744 - mean_absolute_error: 0.1586 - val_loss: 0.1242 - val_mean_absolute_error: 0.1911\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0841 - mean_absolute_error: 0.1658 - val_loss: 0.1287 - val_mean_absolute_error: 0.2008\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0785 - mean_absolute_error: 0.1625 - val_loss: 0.1252 - val_mean_absolute_error: 0.1893\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0747 - mean_absolute_error: 0.1587 - val_loss: 0.1451 - val_mean_absolute_error: 0.2109\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0854 - mean_absolute_error: 0.1650 - val_loss: 0.1251 - val_mean_absolute_error: 0.1929\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0736 - mean_absolute_error: 0.1579 - val_loss: 0.1291 - val_mean_absolute_error: 0.1948\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0751 - mean_absolute_error: 0.1595 - val_loss: 0.1319 - val_mean_absolute_error: 0.1941\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0728 - mean_absolute_error: 0.1580 - val_loss: 0.1317 - val_mean_absolute_error: 0.1952\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0731 - mean_absolute_error: 0.1578 - val_loss: 0.1255 - val_mean_absolute_error: 0.1943\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0754 - mean_absolute_error: 0.1595 - val_loss: 0.1315 - val_mean_absolute_error: 0.1953\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0769 - mean_absolute_error: 0.1610 - val_loss: 0.1291 - val_mean_absolute_error: 0.1949\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 887us/step - loss: 0.0794 - mean_absolute_error: 0.1650 - val_loss: 0.1277 - val_mean_absolute_error: 0.1958\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0786 - mean_absolute_error: 0.1628 - val_loss: 0.1225 - val_mean_absolute_error: 0.1897\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0771 - mean_absolute_error: 0.1605 - val_loss: 0.1377 - val_mean_absolute_error: 0.1968\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0744 - mean_absolute_error: 0.1582 - val_loss: 0.1294 - val_mean_absolute_error: 0.2001\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0764 - mean_absolute_error: 0.1609 - val_loss: 0.1305 - val_mean_absolute_error: 0.1941\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0767 - mean_absolute_error: 0.1615 - val_loss: 0.1360 - val_mean_absolute_error: 0.2062\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0761 - mean_absolute_error: 0.1607 - val_loss: 0.1295 - val_mean_absolute_error: 0.1919\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 876us/step - loss: 0.0738 - mean_absolute_error: 0.1591 - val_loss: 0.1243 - val_mean_absolute_error: 0.1939\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0762 - mean_absolute_error: 0.1608 - val_loss: 0.1226 - val_mean_absolute_error: 0.1904\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0796 - mean_absolute_error: 0.1635 - val_loss: 0.1312 - val_mean_absolute_error: 0.1955\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0758 - mean_absolute_error: 0.1605 - val_loss: 0.1304 - val_mean_absolute_error: 0.1956\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0727 - mean_absolute_error: 0.1570 - val_loss: 0.1245 - val_mean_absolute_error: 0.1913\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0867 - mean_absolute_error: 0.1674 - val_loss: 0.1265 - val_mean_absolute_error: 0.1938\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0740 - mean_absolute_error: 0.1586 - val_loss: 0.1430 - val_mean_absolute_error: 0.2012\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0823 - mean_absolute_error: 0.1669 - val_loss: 0.1287 - val_mean_absolute_error: 0.1939\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0737 - mean_absolute_error: 0.1582 - val_loss: 0.1214 - val_mean_absolute_error: 0.1900\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0779 - mean_absolute_error: 0.1611 - val_loss: 0.1217 - val_mean_absolute_error: 0.1953\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0790 - mean_absolute_error: 0.1632 - val_loss: 0.1251 - val_mean_absolute_error: 0.1917\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0715 - mean_absolute_error: 0.1563 - val_loss: 0.1269 - val_mean_absolute_error: 0.1921\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0722 - mean_absolute_error: 0.1564 - val_loss: 0.1241 - val_mean_absolute_error: 0.1913\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0749 - mean_absolute_error: 0.1595 - val_loss: 0.1249 - val_mean_absolute_error: 0.1939\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0719 - mean_absolute_error: 0.1563 - val_loss: 0.1227 - val_mean_absolute_error: 0.1901\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 891us/step - loss: 0.0756 - mean_absolute_error: 0.1593 - val_loss: 0.1335 - val_mean_absolute_error: 0.1969\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0737 - mean_absolute_error: 0.1575 - val_loss: 0.1267 - val_mean_absolute_error: 0.1976\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0741 - mean_absolute_error: 0.1582 - val_loss: 0.1243 - val_mean_absolute_error: 0.1922\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0767 - mean_absolute_error: 0.1612 - val_loss: 0.1418 - val_mean_absolute_error: 0.1955\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0760 - mean_absolute_error: 0.1602 - val_loss: 0.1248 - val_mean_absolute_error: 0.1907\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 866us/step - loss: 0.0761 - mean_absolute_error: 0.1596 - val_loss: 0.1244 - val_mean_absolute_error: 0.1918\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0737 - mean_absolute_error: 0.1580 - val_loss: 0.1337 - val_mean_absolute_error: 0.1951\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0747 - mean_absolute_error: 0.1601 - val_loss: 0.1332 - val_mean_absolute_error: 0.1979\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 832us/step - loss: 0.0743 - mean_absolute_error: 0.1585 - val_loss: 0.1306 - val_mean_absolute_error: 0.1958\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.0728 - mean_absolute_error: 0.1593 - val_loss: 0.1348 - val_mean_absolute_error: 0.1983\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0749 - mean_absolute_error: 0.1588 - val_loss: 0.1419 - val_mean_absolute_error: 0.2042\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0785 - mean_absolute_error: 0.1641 - val_loss: 0.1338 - val_mean_absolute_error: 0.1961\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 930us/step - loss: 0.0721 - mean_absolute_error: 0.1573 - val_loss: 0.1305 - val_mean_absolute_error: 0.1987\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0792 - mean_absolute_error: 0.1628 - val_loss: 0.1261 - val_mean_absolute_error: 0.1930\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 783us/step - loss: 0.0752 - mean_absolute_error: 0.1597 - val_loss: 0.1236 - val_mean_absolute_error: 0.1931\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0728 - mean_absolute_error: 0.1581 - val_loss: 0.1223 - val_mean_absolute_error: 0.1909\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0733 - mean_absolute_error: 0.1580 - val_loss: 0.1307 - val_mean_absolute_error: 0.1995\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0771 - mean_absolute_error: 0.1604 - val_loss: 0.1292 - val_mean_absolute_error: 0.1964\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0740 - mean_absolute_error: 0.1586 - val_loss: 0.1240 - val_mean_absolute_error: 0.1906\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0733 - mean_absolute_error: 0.1588 - val_loss: 0.1297 - val_mean_absolute_error: 0.1958\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0832 - mean_absolute_error: 0.1659 - val_loss: 0.1293 - val_mean_absolute_error: 0.1916\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.0746 - mean_absolute_error: 0.1587 - val_loss: 0.1326 - val_mean_absolute_error: 0.2015\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.0735 - mean_absolute_error: 0.1587 - val_loss: 0.1238 - val_mean_absolute_error: 0.1933\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0712 - mean_absolute_error: 0.1561 - val_loss: 0.1230 - val_mean_absolute_error: 0.1906\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0744 - mean_absolute_error: 0.1592 - val_loss: 0.1291 - val_mean_absolute_error: 0.1968\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0717 - mean_absolute_error: 0.1574 - val_loss: 0.1260 - val_mean_absolute_error: 0.1943\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 906us/step - loss: 0.0740 - mean_absolute_error: 0.1587 - val_loss: 0.1266 - val_mean_absolute_error: 0.1911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2330d882d30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a network model\n",
    "model_3 = keras.Sequential(name='model-3')\n",
    "model_3.add(layers.Dense(64, \n",
    "                         kernel_regularizer=keras.regularizers.l2(0.001), \n",
    "                         activation='relu', input_shape=(21,)))\n",
    "model_3.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
    "model_3.add(layers.Dense(1))\n",
    "\n",
    "# Set the optimizer, loss function and metric function for training\n",
    "model_3.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Set callback function\n",
    "log_dir = os.path.join('lab2-logs', 'model-3')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-3.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "# Train model-3\n",
    "model_3.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model-4: model of adding Dropout: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 34s - loss: 1.3297 - mean_absolute_error: 0.7873WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0120s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.3339s). Check your callbacks.\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.5195 - mean_absolute_error: 0.4634 - val_loss: 0.2703 - val_mean_absolute_error: 0.3157\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3365 - mean_absolute_error: 0.3618 - val_loss: 0.2210 - val_mean_absolute_error: 0.2942\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3000 - mean_absolute_error: 0.3370 - val_loss: 0.2104 - val_mean_absolute_error: 0.2917\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2685 - mean_absolute_error: 0.3166 - val_loss: 0.1862 - val_mean_absolute_error: 0.2729\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2412 - mean_absolute_error: 0.3045 - val_loss: 0.1919 - val_mean_absolute_error: 0.2781\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2259 - mean_absolute_error: 0.2958 - val_loss: 0.1954 - val_mean_absolute_error: 0.2771\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2229 - mean_absolute_error: 0.2913 - val_loss: 0.1804 - val_mean_absolute_error: 0.2630\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2184 - mean_absolute_error: 0.2894 - val_loss: 0.1671 - val_mean_absolute_error: 0.2606\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2088 - mean_absolute_error: 0.2807 - val_loss: 0.1751 - val_mean_absolute_error: 0.2550\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2055 - mean_absolute_error: 0.2802 - val_loss: 0.1479 - val_mean_absolute_error: 0.2396\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2049 - mean_absolute_error: 0.2751 - val_loss: 0.1621 - val_mean_absolute_error: 0.2510\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1984 - mean_absolute_error: 0.2749 - val_loss: 0.1495 - val_mean_absolute_error: 0.2441\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1913 - mean_absolute_error: 0.2713 - val_loss: 0.1665 - val_mean_absolute_error: 0.2537\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1881 - mean_absolute_error: 0.2686 - val_loss: 0.1631 - val_mean_absolute_error: 0.2477\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1784 - mean_absolute_error: 0.2653 - val_loss: 0.1714 - val_mean_absolute_error: 0.2521\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1772 - mean_absolute_error: 0.2642 - val_loss: 0.1547 - val_mean_absolute_error: 0.2468\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1870 - mean_absolute_error: 0.2631 - val_loss: 0.1536 - val_mean_absolute_error: 0.2370\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1754 - mean_absolute_error: 0.2615 - val_loss: 0.1517 - val_mean_absolute_error: 0.2402\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1738 - mean_absolute_error: 0.2571 - val_loss: 0.1473 - val_mean_absolute_error: 0.2359\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1718 - mean_absolute_error: 0.2579 - val_loss: 0.1536 - val_mean_absolute_error: 0.2465\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1749 - mean_absolute_error: 0.2559 - val_loss: 0.1392 - val_mean_absolute_error: 0.2329\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1875 - mean_absolute_error: 0.2589 - val_loss: 0.1418 - val_mean_absolute_error: 0.2329\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1643 - mean_absolute_error: 0.2538 - val_loss: 0.1528 - val_mean_absolute_error: 0.2390\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1633 - mean_absolute_error: 0.2537 - val_loss: 0.1506 - val_mean_absolute_error: 0.2373\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1587 - mean_absolute_error: 0.2513 - val_loss: 0.1372 - val_mean_absolute_error: 0.2322\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1739 - mean_absolute_error: 0.2513 - val_loss: 0.1591 - val_mean_absolute_error: 0.2372\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1584 - mean_absolute_error: 0.2489 - val_loss: 0.1324 - val_mean_absolute_error: 0.2270\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1698 - mean_absolute_error: 0.2527 - val_loss: 0.1358 - val_mean_absolute_error: 0.2300\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1706 - mean_absolute_error: 0.2509 - val_loss: 0.1407 - val_mean_absolute_error: 0.2342\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1668 - mean_absolute_error: 0.2505 - val_loss: 0.1488 - val_mean_absolute_error: 0.2392\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1599 - mean_absolute_error: 0.2496 - val_loss: 0.1318 - val_mean_absolute_error: 0.2260\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1503 - mean_absolute_error: 0.2461 - val_loss: 0.1308 - val_mean_absolute_error: 0.2246\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1570 - mean_absolute_error: 0.2480 - val_loss: 0.1519 - val_mean_absolute_error: 0.2359\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1524 - mean_absolute_error: 0.2448 - val_loss: 0.1452 - val_mean_absolute_error: 0.2334\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1519 - mean_absolute_error: 0.2451 - val_loss: 0.1375 - val_mean_absolute_error: 0.2292\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1523 - mean_absolute_error: 0.2439 - val_loss: 0.1309 - val_mean_absolute_error: 0.2291\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1465 - mean_absolute_error: 0.2428 - val_loss: 0.1342 - val_mean_absolute_error: 0.2253\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1517 - mean_absolute_error: 0.2409 - val_loss: 0.1273 - val_mean_absolute_error: 0.2225\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1590 - mean_absolute_error: 0.2442 - val_loss: 0.1256 - val_mean_absolute_error: 0.2166\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1532 - mean_absolute_error: 0.2451 - val_loss: 0.1570 - val_mean_absolute_error: 0.2342\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1403 - mean_absolute_error: 0.2379 - val_loss: 0.1314 - val_mean_absolute_error: 0.2203\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1502 - mean_absolute_error: 0.2406 - val_loss: 0.1387 - val_mean_absolute_error: 0.2260\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1398 - mean_absolute_error: 0.2387 - val_loss: 0.1296 - val_mean_absolute_error: 0.2217\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1473 - mean_absolute_error: 0.2406 - val_loss: 0.1331 - val_mean_absolute_error: 0.2236\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1384 - mean_absolute_error: 0.2375 - val_loss: 0.1275 - val_mean_absolute_error: 0.2234\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1510 - mean_absolute_error: 0.2389 - val_loss: 0.1459 - val_mean_absolute_error: 0.2299\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1376 - mean_absolute_error: 0.2390 - val_loss: 0.1340 - val_mean_absolute_error: 0.2178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1542 - mean_absolute_error: 0.2383 - val_loss: 0.1358 - val_mean_absolute_error: 0.2236\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1383 - mean_absolute_error: 0.2359 - val_loss: 0.1387 - val_mean_absolute_error: 0.2288\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1399 - mean_absolute_error: 0.2367 - val_loss: 0.1257 - val_mean_absolute_error: 0.2230\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1383 - mean_absolute_error: 0.2356 - val_loss: 0.1422 - val_mean_absolute_error: 0.2342\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1334 - mean_absolute_error: 0.2349 - val_loss: 0.1283 - val_mean_absolute_error: 0.2185\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1356 - mean_absolute_error: 0.2354 - val_loss: 0.1302 - val_mean_absolute_error: 0.2243\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1415 - mean_absolute_error: 0.2367 - val_loss: 0.1289 - val_mean_absolute_error: 0.2213\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1425 - mean_absolute_error: 0.2369 - val_loss: 0.1238 - val_mean_absolute_error: 0.2221\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1311 - mean_absolute_error: 0.2314 - val_loss: 0.1401 - val_mean_absolute_error: 0.2349\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1396 - mean_absolute_error: 0.2350 - val_loss: 0.1231 - val_mean_absolute_error: 0.2141\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1403 - mean_absolute_error: 0.2341 - val_loss: 0.1329 - val_mean_absolute_error: 0.2200\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1396 - mean_absolute_error: 0.2354 - val_loss: 0.1264 - val_mean_absolute_error: 0.2187\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1434 - mean_absolute_error: 0.2352 - val_loss: 0.1326 - val_mean_absolute_error: 0.2241\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1361 - mean_absolute_error: 0.2329 - val_loss: 0.1463 - val_mean_absolute_error: 0.2287\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1330 - mean_absolute_error: 0.2320 - val_loss: 0.1286 - val_mean_absolute_error: 0.2184\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1417 - mean_absolute_error: 0.2336 - val_loss: 0.1243 - val_mean_absolute_error: 0.2155\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1350 - mean_absolute_error: 0.2321 - val_loss: 0.1335 - val_mean_absolute_error: 0.2239\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1289 - mean_absolute_error: 0.2320 - val_loss: 0.1289 - val_mean_absolute_error: 0.2267\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1323 - mean_absolute_error: 0.2329 - val_loss: 0.1369 - val_mean_absolute_error: 0.2194\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1373 - mean_absolute_error: 0.2337 - val_loss: 0.1253 - val_mean_absolute_error: 0.2191\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1315 - mean_absolute_error: 0.2320 - val_loss: 0.1386 - val_mean_absolute_error: 0.2226\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1387 - mean_absolute_error: 0.2364 - val_loss: 0.1458 - val_mean_absolute_error: 0.2234\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1416 - mean_absolute_error: 0.2341 - val_loss: 0.1257 - val_mean_absolute_error: 0.2144\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1362 - mean_absolute_error: 0.2336 - val_loss: 0.1199 - val_mean_absolute_error: 0.2154\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1401 - mean_absolute_error: 0.2330 - val_loss: 0.1351 - val_mean_absolute_error: 0.2208\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1297 - mean_absolute_error: 0.2315 - val_loss: 0.1396 - val_mean_absolute_error: 0.2265\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1416 - mean_absolute_error: 0.2341 - val_loss: 0.1240 - val_mean_absolute_error: 0.2214\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1358 - mean_absolute_error: 0.2327 - val_loss: 0.1269 - val_mean_absolute_error: 0.2317\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1390 - mean_absolute_error: 0.2360 - val_loss: 0.1199 - val_mean_absolute_error: 0.2150\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1303 - mean_absolute_error: 0.2309 - val_loss: 0.1301 - val_mean_absolute_error: 0.2172\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1352 - mean_absolute_error: 0.2297 - val_loss: 0.1245 - val_mean_absolute_error: 0.2171\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1297 - mean_absolute_error: 0.2292 - val_loss: 0.1248 - val_mean_absolute_error: 0.2133\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1290 - mean_absolute_error: 0.2314 - val_loss: 0.1325 - val_mean_absolute_error: 0.2347\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1354 - mean_absolute_error: 0.2311 - val_loss: 0.1314 - val_mean_absolute_error: 0.2259\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1432 - mean_absolute_error: 0.2331 - val_loss: 0.1219 - val_mean_absolute_error: 0.2205\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1291 - mean_absolute_error: 0.2290 - val_loss: 0.1255 - val_mean_absolute_error: 0.2209\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1337 - mean_absolute_error: 0.2303 - val_loss: 0.1237 - val_mean_absolute_error: 0.2140\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1298 - mean_absolute_error: 0.2291 - val_loss: 0.1336 - val_mean_absolute_error: 0.2271\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.2297 - val_loss: 0.1261 - val_mean_absolute_error: 0.2259\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1168 - mean_absolute_error: 0.2255 - val_loss: 0.1256 - val_mean_absolute_error: 0.2198\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1309 - mean_absolute_error: 0.2294 - val_loss: 0.1342 - val_mean_absolute_error: 0.2153\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.2272 - val_loss: 0.1266 - val_mean_absolute_error: 0.2194\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1338 - mean_absolute_error: 0.2294 - val_loss: 0.1312 - val_mean_absolute_error: 0.2217\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.2284 - val_loss: 0.1371 - val_mean_absolute_error: 0.2331\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.2267 - val_loss: 0.1237 - val_mean_absolute_error: 0.2250\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.2249 - val_loss: 0.1227 - val_mean_absolute_error: 0.2198\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1254 - mean_absolute_error: 0.2240 - val_loss: 0.1228 - val_mean_absolute_error: 0.2219\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.2272 - val_loss: 0.1211 - val_mean_absolute_error: 0.2172\n",
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1306 - mean_absolute_error: 0.2287 - val_loss: 0.1210 - val_mean_absolute_error: 0.2158\n",
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.2264 - val_loss: 0.1316 - val_mean_absolute_error: 0.2237\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.2261 - val_loss: 0.1246 - val_mean_absolute_error: 0.2189\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1330 - mean_absolute_error: 0.2279 - val_loss: 0.1202 - val_mean_absolute_error: 0.2236\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1257 - mean_absolute_error: 0.2262 - val_loss: 0.1222 - val_mean_absolute_error: 0.2278\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1195 - mean_absolute_error: 0.2238 - val_loss: 0.1182 - val_mean_absolute_error: 0.2217\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1497 - mean_absolute_error: 0.2332 - val_loss: 0.1271 - val_mean_absolute_error: 0.2249\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1283 - mean_absolute_error: 0.2268 - val_loss: 0.1239 - val_mean_absolute_error: 0.2297\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.2256 - val_loss: 0.1250 - val_mean_absolute_error: 0.2266\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.2245 - val_loss: 0.1246 - val_mean_absolute_error: 0.2137\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1173 - mean_absolute_error: 0.2242 - val_loss: 0.1215 - val_mean_absolute_error: 0.2181\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1329 - mean_absolute_error: 0.2303 - val_loss: 0.1290 - val_mean_absolute_error: 0.2279\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1322 - mean_absolute_error: 0.2267 - val_loss: 0.1321 - val_mean_absolute_error: 0.2282\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.2254 - val_loss: 0.1375 - val_mean_absolute_error: 0.2272\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.2251 - val_loss: 0.1234 - val_mean_absolute_error: 0.2140\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.2270 - val_loss: 0.1342 - val_mean_absolute_error: 0.2293\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1202 - mean_absolute_error: 0.2257 - val_loss: 0.1233 - val_mean_absolute_error: 0.2196\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.2262 - val_loss: 0.1252 - val_mean_absolute_error: 0.2240\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.2233 - val_loss: 0.1238 - val_mean_absolute_error: 0.2251\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1172 - mean_absolute_error: 0.2231 - val_loss: 0.1255 - val_mean_absolute_error: 0.2223\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1183 - mean_absolute_error: 0.2227 - val_loss: 0.1254 - val_mean_absolute_error: 0.2264\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1154 - mean_absolute_error: 0.2222 - val_loss: 0.1402 - val_mean_absolute_error: 0.2364\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1209 - mean_absolute_error: 0.2220 - val_loss: 0.1296 - val_mean_absolute_error: 0.2240\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1217 - mean_absolute_error: 0.2255 - val_loss: 0.1224 - val_mean_absolute_error: 0.2213\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1168 - mean_absolute_error: 0.2221 - val_loss: 0.1253 - val_mean_absolute_error: 0.2283\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1152 - mean_absolute_error: 0.2234 - val_loss: 0.1165 - val_mean_absolute_error: 0.2167\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1179 - mean_absolute_error: 0.2246 - val_loss: 0.1220 - val_mean_absolute_error: 0.2278\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1242 - mean_absolute_error: 0.2265 - val_loss: 0.1275 - val_mean_absolute_error: 0.2227\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.2242 - val_loss: 0.1240 - val_mean_absolute_error: 0.2200\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1225 - mean_absolute_error: 0.2230 - val_loss: 0.1281 - val_mean_absolute_error: 0.2246\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.2245 - val_loss: 0.1231 - val_mean_absolute_error: 0.2255\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1143 - mean_absolute_error: 0.2204 - val_loss: 0.1176 - val_mean_absolute_error: 0.2215\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1147 - mean_absolute_error: 0.2210 - val_loss: 0.1226 - val_mean_absolute_error: 0.2268\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1187 - mean_absolute_error: 0.2237 - val_loss: 0.1177 - val_mean_absolute_error: 0.2122\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 975us/step - loss: 0.1235 - mean_absolute_error: 0.2235 - val_loss: 0.1332 - val_mean_absolute_error: 0.2326\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.2227 - val_loss: 0.1319 - val_mean_absolute_error: 0.2383\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.2227 - val_loss: 0.1298 - val_mean_absolute_error: 0.2281\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1157 - mean_absolute_error: 0.2199 - val_loss: 0.1210 - val_mean_absolute_error: 0.2249\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1208 - mean_absolute_error: 0.2231 - val_loss: 0.1260 - val_mean_absolute_error: 0.2272\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1203 - mean_absolute_error: 0.2235 - val_loss: 0.1322 - val_mean_absolute_error: 0.2184\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1205 - mean_absolute_error: 0.2223 - val_loss: 0.1209 - val_mean_absolute_error: 0.2161\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1062 - mean_absolute_error: 0.2179 - val_loss: 0.1217 - val_mean_absolute_error: 0.2207\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1206 - mean_absolute_error: 0.2220 - val_loss: 0.1205 - val_mean_absolute_error: 0.2130\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.2233 - val_loss: 0.1253 - val_mean_absolute_error: 0.2320\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1119 - mean_absolute_error: 0.2193 - val_loss: 0.1215 - val_mean_absolute_error: 0.2254\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1177 - mean_absolute_error: 0.2221 - val_loss: 0.1167 - val_mean_absolute_error: 0.2227\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1175 - mean_absolute_error: 0.2200 - val_loss: 0.1332 - val_mean_absolute_error: 0.2261\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1172 - mean_absolute_error: 0.2205 - val_loss: 0.1174 - val_mean_absolute_error: 0.2229\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1161 - mean_absolute_error: 0.2205 - val_loss: 0.1210 - val_mean_absolute_error: 0.2221\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.2210 - val_loss: 0.1218 - val_mean_absolute_error: 0.2260\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.2228 - val_loss: 0.1239 - val_mean_absolute_error: 0.2227\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1168 - mean_absolute_error: 0.2212 - val_loss: 0.1257 - val_mean_absolute_error: 0.2213\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_error: 0.2208 - val_loss: 0.1196 - val_mean_absolute_error: 0.2259\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1187 - mean_absolute_error: 0.2207 - val_loss: 0.1277 - val_mean_absolute_error: 0.2194\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1142 - mean_absolute_error: 0.2210 - val_loss: 0.1284 - val_mean_absolute_error: 0.2226\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1118 - mean_absolute_error: 0.2198 - val_loss: 0.1277 - val_mean_absolute_error: 0.2232\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.2214 - val_loss: 0.1180 - val_mean_absolute_error: 0.2177\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1169 - mean_absolute_error: 0.2207 - val_loss: 0.1197 - val_mean_absolute_error: 0.2157\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1158 - mean_absolute_error: 0.2192 - val_loss: 0.1396 - val_mean_absolute_error: 0.2295\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1156 - mean_absolute_error: 0.2189 - val_loss: 0.1206 - val_mean_absolute_error: 0.2168\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1153 - mean_absolute_error: 0.2207 - val_loss: 0.1221 - val_mean_absolute_error: 0.2228\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1130 - mean_absolute_error: 0.2196 - val_loss: 0.1287 - val_mean_absolute_error: 0.2313\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1152 - mean_absolute_error: 0.2189 - val_loss: 0.1184 - val_mean_absolute_error: 0.2081\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1153 - mean_absolute_error: 0.2214 - val_loss: 0.1205 - val_mean_absolute_error: 0.2126\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1179 - mean_absolute_error: 0.2204 - val_loss: 0.1351 - val_mean_absolute_error: 0.2365\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1214 - mean_absolute_error: 0.2206 - val_loss: 0.1246 - val_mean_absolute_error: 0.2286\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1197 - mean_absolute_error: 0.2219 - val_loss: 0.1296 - val_mean_absolute_error: 0.2294\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1144 - mean_absolute_error: 0.2191 - val_loss: 0.1162 - val_mean_absolute_error: 0.2170\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1094 - mean_absolute_error: 0.2181 - val_loss: 0.1373 - val_mean_absolute_error: 0.2176\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1104 - mean_absolute_error: 0.2175 - val_loss: 0.1279 - val_mean_absolute_error: 0.2289\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1157 - mean_absolute_error: 0.2190 - val_loss: 0.1336 - val_mean_absolute_error: 0.2318\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1163 - mean_absolute_error: 0.2201 - val_loss: 0.1184 - val_mean_absolute_error: 0.2178\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1155 - mean_absolute_error: 0.2202 - val_loss: 0.1287 - val_mean_absolute_error: 0.2380\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1142 - mean_absolute_error: 0.2178 - val_loss: 0.1198 - val_mean_absolute_error: 0.2305\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1164 - mean_absolute_error: 0.2200 - val_loss: 0.1242 - val_mean_absolute_error: 0.2191\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1134 - mean_absolute_error: 0.2180 - val_loss: 0.1223 - val_mean_absolute_error: 0.2206\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1202 - mean_absolute_error: 0.2213 - val_loss: 0.1308 - val_mean_absolute_error: 0.2380\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1154 - mean_absolute_error: 0.2191 - val_loss: 0.1218 - val_mean_absolute_error: 0.2190\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1275 - mean_absolute_error: 0.2222 - val_loss: 0.1336 - val_mean_absolute_error: 0.2386\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1116 - mean_absolute_error: 0.2175 - val_loss: 0.1213 - val_mean_absolute_error: 0.2206\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1156 - mean_absolute_error: 0.2182 - val_loss: 0.1239 - val_mean_absolute_error: 0.2203\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1156 - mean_absolute_error: 0.2184 - val_loss: 0.1262 - val_mean_absolute_error: 0.2210\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1102 - mean_absolute_error: 0.2185 - val_loss: 0.1217 - val_mean_absolute_error: 0.2155\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1060 - mean_absolute_error: 0.2165 - val_loss: 0.1242 - val_mean_absolute_error: 0.2252\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1232 - mean_absolute_error: 0.2204 - val_loss: 0.1218 - val_mean_absolute_error: 0.2201\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1118 - mean_absolute_error: 0.2193 - val_loss: 0.1263 - val_mean_absolute_error: 0.2267\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1116 - mean_absolute_error: 0.2186 - val_loss: 0.1198 - val_mean_absolute_error: 0.2145\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1148 - mean_absolute_error: 0.2174 - val_loss: 0.1138 - val_mean_absolute_error: 0.2194\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1119 - mean_absolute_error: 0.2169 - val_loss: 0.1211 - val_mean_absolute_error: 0.2227\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1194 - mean_absolute_error: 0.2195 - val_loss: 0.1303 - val_mean_absolute_error: 0.2257\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1121 - mean_absolute_error: 0.2177 - val_loss: 0.1185 - val_mean_absolute_error: 0.2138\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1200 - mean_absolute_error: 0.2200 - val_loss: 0.1146 - val_mean_absolute_error: 0.2173\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1178 - mean_absolute_error: 0.2206 - val_loss: 0.1224 - val_mean_absolute_error: 0.2178\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1125 - mean_absolute_error: 0.2186 - val_loss: 0.1245 - val_mean_absolute_error: 0.2140\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1099 - mean_absolute_error: 0.2187 - val_loss: 0.1114 - val_mean_absolute_error: 0.2092\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1099 - mean_absolute_error: 0.2152 - val_loss: 0.1176 - val_mean_absolute_error: 0.2210\n",
      "Epoch 192/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1155 - mean_absolute_error: 0.2192 - val_loss: 0.1186 - val_mean_absolute_error: 0.2180\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1081 - mean_absolute_error: 0.2168 - val_loss: 0.1237 - val_mean_absolute_error: 0.2246\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1284 - mean_absolute_error: 0.2218 - val_loss: 0.1382 - val_mean_absolute_error: 0.2314\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1138 - mean_absolute_error: 0.2169 - val_loss: 0.1253 - val_mean_absolute_error: 0.2265\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1151 - mean_absolute_error: 0.2186 - val_loss: 0.1307 - val_mean_absolute_error: 0.2327\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1113 - mean_absolute_error: 0.2165 - val_loss: 0.1274 - val_mean_absolute_error: 0.2290\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1107 - mean_absolute_error: 0.2159 - val_loss: 0.1145 - val_mean_absolute_error: 0.2117\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1167 - mean_absolute_error: 0.2189 - val_loss: 0.1202 - val_mean_absolute_error: 0.2161\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_error: 0.2175 - val_loss: 0.1194 - val_mean_absolute_error: 0.2160\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1074 - mean_absolute_error: 0.2166 - val_loss: 0.1324 - val_mean_absolute_error: 0.2153\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1188 - mean_absolute_error: 0.2185 - val_loss: 0.1184 - val_mean_absolute_error: 0.2174\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1150 - mean_absolute_error: 0.2190 - val_loss: 0.1318 - val_mean_absolute_error: 0.2200\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1346 - mean_absolute_error: 0.2212 - val_loss: 0.1269 - val_mean_absolute_error: 0.2199\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1088 - mean_absolute_error: 0.2167 - val_loss: 0.1273 - val_mean_absolute_error: 0.2240\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1096 - mean_absolute_error: 0.2162 - val_loss: 0.1192 - val_mean_absolute_error: 0.2123\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1172 - mean_absolute_error: 0.2191 - val_loss: 0.1225 - val_mean_absolute_error: 0.2264\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1111 - mean_absolute_error: 0.2164 - val_loss: 0.1202 - val_mean_absolute_error: 0.2262\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1129 - mean_absolute_error: 0.2182 - val_loss: 0.1413 - val_mean_absolute_error: 0.2319\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1068 - mean_absolute_error: 0.2130 - val_loss: 0.1160 - val_mean_absolute_error: 0.2163\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1062 - mean_absolute_error: 0.2149 - val_loss: 0.1175 - val_mean_absolute_error: 0.2167\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1163 - mean_absolute_error: 0.2177 - val_loss: 0.1250 - val_mean_absolute_error: 0.2338\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1118 - mean_absolute_error: 0.2157 - val_loss: 0.1237 - val_mean_absolute_error: 0.2176\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1129 - mean_absolute_error: 0.2174 - val_loss: 0.1426 - val_mean_absolute_error: 0.2242\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1142 - mean_absolute_error: 0.2173 - val_loss: 0.1320 - val_mean_absolute_error: 0.2170\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1321 - mean_absolute_error: 0.2220 - val_loss: 0.1348 - val_mean_absolute_error: 0.2269\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1135 - mean_absolute_error: 0.2186 - val_loss: 0.1434 - val_mean_absolute_error: 0.2318\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1111 - mean_absolute_error: 0.2173 - val_loss: 0.1212 - val_mean_absolute_error: 0.2215\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1123 - mean_absolute_error: 0.2147 - val_loss: 0.1252 - val_mean_absolute_error: 0.2248\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1170 - mean_absolute_error: 0.2162 - val_loss: 0.1253 - val_mean_absolute_error: 0.2233\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1155 - mean_absolute_error: 0.2188 - val_loss: 0.1242 - val_mean_absolute_error: 0.2199\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1112 - mean_absolute_error: 0.2147 - val_loss: 0.1144 - val_mean_absolute_error: 0.2203\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_error: 0.2157 - val_loss: 0.1228 - val_mean_absolute_error: 0.2284\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1076 - mean_absolute_error: 0.2153 - val_loss: 0.1268 - val_mean_absolute_error: 0.2314\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1077 - mean_absolute_error: 0.2148 - val_loss: 0.1289 - val_mean_absolute_error: 0.2222\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1087 - mean_absolute_error: 0.2148 - val_loss: 0.1259 - val_mean_absolute_error: 0.2190\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1136 - mean_absolute_error: 0.2168 - val_loss: 0.1199 - val_mean_absolute_error: 0.2220\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1174 - mean_absolute_error: 0.2192 - val_loss: 0.1162 - val_mean_absolute_error: 0.2174\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1070 - mean_absolute_error: 0.2157 - val_loss: 0.1231 - val_mean_absolute_error: 0.2203\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1075 - mean_absolute_error: 0.2163 - val_loss: 0.1170 - val_mean_absolute_error: 0.2111\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1137 - mean_absolute_error: 0.2173 - val_loss: 0.1183 - val_mean_absolute_error: 0.2236\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1176 - mean_absolute_error: 0.2169 - val_loss: 0.1193 - val_mean_absolute_error: 0.2165\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1120 - mean_absolute_error: 0.2169 - val_loss: 0.1285 - val_mean_absolute_error: 0.2268\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1175 - mean_absolute_error: 0.2164 - val_loss: 0.1143 - val_mean_absolute_error: 0.2158\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1096 - mean_absolute_error: 0.2131 - val_loss: 0.1157 - val_mean_absolute_error: 0.2191\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1065 - mean_absolute_error: 0.2142 - val_loss: 0.1326 - val_mean_absolute_error: 0.2287\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1098 - mean_absolute_error: 0.2161 - val_loss: 0.1197 - val_mean_absolute_error: 0.2112\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1139 - mean_absolute_error: 0.2173 - val_loss: 0.1226 - val_mean_absolute_error: 0.2262\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1120 - mean_absolute_error: 0.2165 - val_loss: 0.1369 - val_mean_absolute_error: 0.2405\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1081 - mean_absolute_error: 0.2152 - val_loss: 0.1309 - val_mean_absolute_error: 0.2313\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1108 - mean_absolute_error: 0.2151 - val_loss: 0.1219 - val_mean_absolute_error: 0.2178\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1167 - mean_absolute_error: 0.2168 - val_loss: 0.1214 - val_mean_absolute_error: 0.2217\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1121 - mean_absolute_error: 0.2148 - val_loss: 0.1216 - val_mean_absolute_error: 0.2075\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1090 - mean_absolute_error: 0.2130 - val_loss: 0.1167 - val_mean_absolute_error: 0.2112\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1059 - mean_absolute_error: 0.2139 - val_loss: 0.1200 - val_mean_absolute_error: 0.2195\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1132 - mean_absolute_error: 0.2172 - val_loss: 0.1157 - val_mean_absolute_error: 0.2146\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1113 - mean_absolute_error: 0.2165 - val_loss: 0.1182 - val_mean_absolute_error: 0.2196\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1078 - mean_absolute_error: 0.2151 - val_loss: 0.1175 - val_mean_absolute_error: 0.2191\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1158 - mean_absolute_error: 0.2163 - val_loss: 0.1599 - val_mean_absolute_error: 0.2347\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1121 - mean_absolute_error: 0.2165 - val_loss: 0.1143 - val_mean_absolute_error: 0.2079\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1106 - mean_absolute_error: 0.2156 - val_loss: 0.1179 - val_mean_absolute_error: 0.2209\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1119 - mean_absolute_error: 0.2151 - val_loss: 0.1277 - val_mean_absolute_error: 0.2238\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1081 - mean_absolute_error: 0.2145 - val_loss: 0.1180 - val_mean_absolute_error: 0.2222\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1055 - mean_absolute_error: 0.2143 - val_loss: 0.1257 - val_mean_absolute_error: 0.2210\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1076 - mean_absolute_error: 0.2145 - val_loss: 0.1235 - val_mean_absolute_error: 0.2288\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1060 - mean_absolute_error: 0.2144 - val_loss: 0.1331 - val_mean_absolute_error: 0.2226\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1088 - mean_absolute_error: 0.2149 - val_loss: 0.1199 - val_mean_absolute_error: 0.2117\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1095 - mean_absolute_error: 0.2137 - val_loss: 0.1189 - val_mean_absolute_error: 0.2306\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1109 - mean_absolute_error: 0.2154 - val_loss: 0.1203 - val_mean_absolute_error: 0.2338\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1112 - mean_absolute_error: 0.2154 - val_loss: 0.1250 - val_mean_absolute_error: 0.2213\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1135 - mean_absolute_error: 0.2166 - val_loss: 0.1335 - val_mean_absolute_error: 0.2190\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1088 - mean_absolute_error: 0.2153 - val_loss: 0.1151 - val_mean_absolute_error: 0.2109\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1078 - mean_absolute_error: 0.2160 - val_loss: 0.1340 - val_mean_absolute_error: 0.2258\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1037 - mean_absolute_error: 0.2127 - val_loss: 0.1208 - val_mean_absolute_error: 0.2210\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1100 - mean_absolute_error: 0.2141 - val_loss: 0.1190 - val_mean_absolute_error: 0.2268\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1076 - mean_absolute_error: 0.2162 - val_loss: 0.1239 - val_mean_absolute_error: 0.2222\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1075 - mean_absolute_error: 0.2146 - val_loss: 0.1220 - val_mean_absolute_error: 0.2257\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1078 - mean_absolute_error: 0.2143 - val_loss: 0.1188 - val_mean_absolute_error: 0.2237\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1080 - mean_absolute_error: 0.2141 - val_loss: 0.1373 - val_mean_absolute_error: 0.2279\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1044 - mean_absolute_error: 0.2139 - val_loss: 0.1191 - val_mean_absolute_error: 0.2209\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1072 - mean_absolute_error: 0.2147 - val_loss: 0.1132 - val_mean_absolute_error: 0.2050\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1095 - mean_absolute_error: 0.2131 - val_loss: 0.1228 - val_mean_absolute_error: 0.2141\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1324 - mean_absolute_error: 0.2201 - val_loss: 0.1213 - val_mean_absolute_error: 0.2153\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1099 - mean_absolute_error: 0.2136 - val_loss: 0.1208 - val_mean_absolute_error: 0.2215\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1109 - mean_absolute_error: 0.2148 - val_loss: 0.1196 - val_mean_absolute_error: 0.2251\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1129 - mean_absolute_error: 0.2180 - val_loss: 0.1203 - val_mean_absolute_error: 0.2250\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1070 - mean_absolute_error: 0.2135 - val_loss: 0.1189 - val_mean_absolute_error: 0.2192\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_error: 0.2165 - val_loss: 0.1239 - val_mean_absolute_error: 0.2246\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1057 - mean_absolute_error: 0.2122 - val_loss: 0.1220 - val_mean_absolute_error: 0.2227\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1073 - mean_absolute_error: 0.2140 - val_loss: 0.1265 - val_mean_absolute_error: 0.2305\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1141 - mean_absolute_error: 0.2163 - val_loss: 0.1122 - val_mean_absolute_error: 0.2130\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1148 - mean_absolute_error: 0.2161 - val_loss: 0.1244 - val_mean_absolute_error: 0.2160\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1141 - mean_absolute_error: 0.2179 - val_loss: 0.1141 - val_mean_absolute_error: 0.2183\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1179 - mean_absolute_error: 0.2166 - val_loss: 0.1308 - val_mean_absolute_error: 0.2305\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1151 - mean_absolute_error: 0.2169 - val_loss: 0.1254 - val_mean_absolute_error: 0.2187\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1088 - mean_absolute_error: 0.2157 - val_loss: 0.1206 - val_mean_absolute_error: 0.2196\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1133 - mean_absolute_error: 0.2150 - val_loss: 0.1226 - val_mean_absolute_error: 0.2249\n",
      "Epoch 288/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1105 - mean_absolute_error: 0.2144 - val_loss: 0.1275 - val_mean_absolute_error: 0.2184\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1073 - mean_absolute_error: 0.2156 - val_loss: 0.1168 - val_mean_absolute_error: 0.2078\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1011 - mean_absolute_error: 0.2120 - val_loss: 0.1271 - val_mean_absolute_error: 0.2355\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1099 - mean_absolute_error: 0.2153 - val_loss: 0.1174 - val_mean_absolute_error: 0.2163\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1054 - mean_absolute_error: 0.2123 - val_loss: 0.1263 - val_mean_absolute_error: 0.2216\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1013 - mean_absolute_error: 0.2114 - val_loss: 0.1213 - val_mean_absolute_error: 0.2172\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1045 - mean_absolute_error: 0.2106 - val_loss: 0.1147 - val_mean_absolute_error: 0.2172\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1119 - mean_absolute_error: 0.2163 - val_loss: 0.1311 - val_mean_absolute_error: 0.2281\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1122 - mean_absolute_error: 0.2150 - val_loss: 0.1196 - val_mean_absolute_error: 0.2241\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1025 - mean_absolute_error: 0.2134 - val_loss: 0.1127 - val_mean_absolute_error: 0.2214\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1121 - mean_absolute_error: 0.2163 - val_loss: 0.1234 - val_mean_absolute_error: 0.2191\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1037 - mean_absolute_error: 0.2118 - val_loss: 0.1176 - val_mean_absolute_error: 0.2120\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1212 - mean_absolute_error: 0.2168 - val_loss: 0.1250 - val_mean_absolute_error: 0.2184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23311338400>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = keras.Sequential(name='model-4')\n",
    "model_4.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "model_4.add(layers.Dropout(0.3))\n",
    "model_4.add(layers.Dense(64, activation='relu'))\n",
    "model_4.add(layers.Dropout(0.3))\n",
    "model_4.add(layers.Dense(1))\n",
    "\n",
    "model_4.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "log_dir = os.path.join('lab2-logs', 'model-4')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-4.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_4.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training, the trained Model-2, Model-3, and Model-4 are verified on the test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2: 13.11%\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.models.load_model('lab2-logs/models/Best-model-2.h5')\n",
    "y_pred = model_2.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_2: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3: 12.81%\n"
     ]
    }
   ],
   "source": [
    "model_3 = keras.models.load_model('lab2-logs/models/Best-model-3.h5')\n",
    "y_pred = model_3.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_3: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4: 13.82%\n"
     ]
    }
   ],
   "source": [
    "model_4 = keras.models.load_model('lab2-logs/models/Best-model-4.h5')\n",
    "y_pred = model_4.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_4: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
